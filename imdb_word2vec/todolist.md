[3 tools called]

---

# ğŸ” æŠ€æœ¯è¯„å®¡æŠ¥å‘Š

**è¯„å®¡äºº**: AI æŠ€æœ¯å®˜ (CTO)  
**é¡¹ç›®**: IMDb Word2Vec ç”µå½±æ¨èç³»ç»Ÿ  
**è¯„å®¡æ—¥æœŸ**: 2024-12-23

---

## ğŸ“Š æ€»ä½“è¯„åˆ†

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| **æ¶æ„è®¾è®¡** | â­â­â­â˜†â˜† (3/5) | æ¨¡å—åŒ–å°šå¯ï¼Œä½†èŒè´£è¾¹ç•Œæ¨¡ç³Š |
| **ä»£ç è´¨é‡** | â­â­â­â­â˜† (4/5) | å¯è¯»æ€§å¥½ï¼Œä½†å­˜åœ¨å†—ä½™ |
| **å·¥ç¨‹å®è·µ** | â­â­â­â˜†â˜† (3/5) | æœ‰é…ç½®ç®¡ç†ï¼Œç¼ºä¹æµ‹è¯•è¦†ç›– |
| **ç®—æ³•é€‰æ‹©** | â­â­â­â˜†â˜† (3/5) | Word2Vec è¿‡æ—¶ï¼Œä½†å®ç°åˆç† |
| **å¯æ‰©å±•æ€§** | â­â­â­â­â˜† (4/5) | æµå¼è®­ç»ƒè®¾è®¡è‰¯å¥½ |

**ç»¼åˆè¯„åˆ†**: **3.4/5** â€” ä¸­ç­‰åä¸Šçš„å­¦ä¹ é¡¹ç›®ï¼Œè·ç¦»ç”Ÿäº§çº§åˆ«è¿˜æœ‰å·®è·

---

## ğŸ¯ ç›®æ ‡åˆ†æ

### å£°ç§°ç›®æ ‡
> ç”µå½±æ¨èç³»ç»Ÿ

### å®é™…å®ç°
> ä¸€ä¸ª Word2Vec åµŒå…¥è®­ç»ƒç®¡é“

### âš ï¸ ç›®æ ‡ä¸å®ç°çš„é¸¿æ²Ÿ

```
å£°ç§°: "ç”µå½±æ¨èç³»ç»Ÿ"
å®é™…: åªæœ‰åµŒå…¥å±‚ï¼Œæ²¡æœ‰æ¨èé€»è¾‘

ç¼ºå¤±ç»„ä»¶:
â”œâ”€â”€ âŒ ç”¨æˆ·ç”»åƒæ¨¡å—
â”œâ”€â”€ âŒ å¬å›å±‚ (Candidate Generation)
â”œâ”€â”€ âŒ ç²¾æ’å±‚ (Ranking)
â”œâ”€â”€ âŒ åœ¨çº¿æœåŠ¡ API
â””â”€â”€ âŒ A/B æµ‹è¯•æ¡†æ¶
```

**æ¯’è¾£ç‚¹è¯„**: è¿™ä¸æ˜¯æ¨èç³»ç»Ÿï¼Œè¿™æ˜¯æ¨èç³»ç»Ÿçš„ **0.1 ä¸ªç»„ä»¶**ã€‚æŠŠè¯å‘é‡è®­ç»ƒç­‰åŒäºæ¨èç³»ç»Ÿï¼Œå°±åƒæŠŠå‘åŠ¨æœºç­‰åŒäºæ±½è½¦ã€‚

---

## ğŸ—ï¸ æ¶æ„è¯„å®¡

### âœ… ä¼˜ç‚¹

1. **æ¨¡å—åŒ–åˆ†ç¦»æ¸…æ™°**
```
preprocess.py     â†’ æ•°æ®æ¸…æ´—
feature_engineering.py â†’ ç‰¹å¾æ„å»º
pretraining.py    â†’ æ ·æœ¬ç”Ÿæˆ
training.py       â†’ æ¨¡å‹è®­ç»ƒ
export.py         â†’ æ¨¡å‹å¯¼å‡º
```

2. **é…ç½®é›†ä¸­ç®¡ç†**
```python
# config.py - è‰¯å¥½å®è·µ
@dataclass
class Config:
    paths: PathConfig
    data: DataConfig
    train: TrainConfig
```

3. **æµå¼è®­ç»ƒè®¾è®¡**
```python
# è§£å†³å†…å­˜ç“¶é¢ˆçš„æ­£ç¡®æ€è·¯
for chunk in chunks:
    train_on_chunk(chunk)
    release_memory()
```

### âŒ é—®é¢˜

#### 1. èŒè´£æ··ä¹±

```python
# feature_engineering.py ä¸­æ··æ‚äº†ï¼š
# - åºåˆ—ç”Ÿæˆ (Word2Vec ç”¨)
# - è¡¨æ ¼ç‰¹å¾ç”Ÿæˆ (Autoencoder ç”¨)
# - è¯è¡¨æ„å»º
# åº”è¯¥æ‹†åˆ†ä¸º 3 ä¸ªæ¨¡å—
```

#### 2. Autoencoder æ¨¡å—å®šä½å°´å°¬

```python
# autoencoder.py çš„é—®é¢˜ï¼š
# 1. è¾“å…¥æ˜¯ tabular_featuresï¼Œè¾“å‡ºä¹Ÿæ˜¯ tabular_features
# 2. ä¸ Word2Vec å®Œå…¨ç‹¬ç«‹ï¼Œæ²¡æœ‰è”åˆè®­ç»ƒ
# 3. ç”Ÿæˆçš„ fused_features æ²¡æœ‰ä¸‹æ¸¸æ¶ˆè´¹è€…

# è¿™ä¸ªæ¨¡å—å­˜åœ¨çš„æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ
```

**æ¯’è¾£ç‚¹è¯„**: Autoencoder åƒæ˜¯ä¸€ä¸ªå­¤å„¿ï¼Œè¢«ç”Ÿä¸‹æ¥å°±æ²¡äººç®¡ã€‚

#### 3. å®ä½“å‰ç¼€è®¾è®¡è¿‡åº¦

```python
ENTITY_PREFIXES = {
    "movie": "MOV_",
    "person": "PER_",
    "actor": "ACT_",    # æ¼”å‘˜
    "director": "DIR_", # å¯¼æ¼”
    # ...
}

# é—®é¢˜ï¼šåŒä¸€ä¸ªäººæ—¢æ˜¯ PER_nm123ï¼Œåˆæ˜¯ ACT_nm123ï¼Œåˆæ˜¯ DIR_nm123
# è¿™ä¸æ˜¯åŒºåˆ†ï¼Œæ˜¯æ··ä¹±
```

---

## ğŸ’» ä»£ç è´¨é‡è¯„å®¡

### âœ… ä¼˜ç‚¹

1. **ç±»å‹æ³¨è§£å®Œæ•´**
```python
def _add_negative_samples(
    targets: np.ndarray,
    contexts: np.ndarray,
    neg_prob: np.ndarray,
    num_ns: int,
    rng: np.random.Generator,
) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
```

2. **æ—¥å¿—è§„èŒƒ**
```python
logger.info("è¯è¡¨è§„æ¨¡: %d", vocab_size)
logger.info("æ•°æ®å—æ•°: %d", num_chunks)
```

### âŒ é—®é¢˜

#### 1. é‡å¤ä»£ç 

```python
# training.py ä¸­ TqdmProgressCallback å®šä¹‰äº†ä¸€æ¬¡
# autoencoder.py ä¸­ TqdmProgressCallback åˆå®šä¹‰äº†ä¸€æ¬¡
# åº”è¯¥æ”¾åˆ° utils.py
```

#### 2. é­”æ³•æ•°å­—

```python
# config.py
subsample_t: float = 1e-4  # ä¸ºä»€ä¹ˆæ˜¯ 1e-4ï¼Ÿ
window_size: int = 5       # ä¸ºä»€ä¹ˆæ˜¯ 5ï¼Ÿ
num_negative_samples: int = 5  # ä¸ºä»€ä¹ˆæ˜¯ 5ï¼Ÿ

# æ²¡æœ‰ä»»ä½•æ–‡æ¡£è¯´æ˜è¿™äº›å€¼çš„æ¥æº
```

#### 3. å¼‚å¸¸å¤„ç†ç¼ºå¤±

```python
# pretraining.py
data = np.load(chunk_path)
return data["targets"], data["contexts"]

# å¦‚æœæ–‡ä»¶æŸåå‘¢ï¼Ÿå¦‚æœ key ä¸å­˜åœ¨å‘¢ï¼Ÿ
# ç”Ÿäº§ä»£ç å¿…é¡»å¤„ç†è¿™äº›æƒ…å†µ
```

#### 4. feature_engineering.py ä¸­å¤§é‡ä½æ•ˆå¾ªç¯

```python
# 793 è¡Œä»£ç ï¼Œå¤§é‡ iterrows()
for _, row in tqdm(staff_df.iterrows(), ...):
    # iterrows æ˜¯ pandas æœ€æ…¢çš„éå†æ–¹å¼
    # åº”è¯¥ç”¨ vectorized æ“ä½œæˆ– apply
```

**æ¯’è¾£ç‚¹è¯„**: `iterrows` æ˜¯ pandas çš„è€»è¾±æŸ±ï¼Œä½ ç”¨äº† 10 æ¬¡ã€‚

---

## ğŸ§® ç®—æ³•è¯„å®¡

### Word2Vec çš„æ—¶ä»£å±€é™

```
2013: Word2Vec å‘å¸ƒ
2018: BERT å‘å¸ƒ
2020: GPT-3 å‘å¸ƒ
2024: ä½ è¿˜åœ¨ç”¨ Word2Vec

é—®é¢˜ï¼š
1. æ— æ³•å¤„ç†å¤šä¹‰è¯ï¼ˆ"è‹¹æœ"æ˜¯æ°´æœè¿˜æ˜¯å…¬å¸ï¼Ÿï¼‰
2. æ— æ³•æ•è·å¥å­çº§è¯­ä¹‰
3. æ— æ³•å¤„ç† OOVï¼ˆOut-of-Vocabularyï¼‰
```

### æ›´å¥½çš„é€‰æ‹©

| æ–¹æ¡ˆ | ä¼˜åŠ¿ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| **GloVe** | å…¨å±€ç»Ÿè®¡ + å…±ç° | é™æ€åµŒå…¥ |
| **FastText** | æ”¯æŒå­è¯ï¼Œå¤„ç† OOV | å½¢æ€ä¸°å¯Œçš„è¯­è¨€ |
| **Sentence-BERT** | å¥å­çº§è¯­ä¹‰ | æ–‡æœ¬ç›¸ä¼¼åº¦ |
| **Two-Tower** | ä¸“ä¸ºæ¨èè®¾è®¡ | å·¥ä¸šçº§æ¨è |

**æ¯’è¾£ç‚¹è¯„**: 2024 å¹´è¿˜åœ¨æ‰‹å†™ Word2Vecï¼Œå°±åƒ 2024 å¹´è¿˜åœ¨ç”¨ç¿»ç›–æ‰‹æœºã€‚èƒ½ç”¨ï¼Œä½†ä¸ºä»€ä¹ˆï¼Ÿ

---

## ğŸ”¬ ç‰¹å¾å·¥ç¨‹è¯„å®¡

### âœ… äº®ç‚¹

```python
# 9 ç§åºåˆ—ç±»å‹ï¼Œè¦†ç›–å¤šç§å…³ç³»
1. äººå‘˜-ç”µå½±åºåˆ—
2. ç”µå½±-ä¸Šä¸‹æ–‡åºåˆ—
3. ç³»åˆ—-å‰§é›†åºåˆ—
4. åˆä½œæ¼”å‘˜åºåˆ—
5. ç±»å‹-ç”µå½±åºåˆ—
6. å¹´ä»£-ç”µå½±åºåˆ—    â† åˆ›æ–°
7. è¯„åˆ†-ç”µå½±åºåˆ—    â† åˆ›æ–°
8. å¯¼æ¼”-ç±»å‹åå¥½    â† åˆ›æ–°
9. æ¼”å‘˜-ç±»å‹åå¥½    â† åˆ›æ–°
```

### âŒ é—®é¢˜

#### 1. è¯„åˆ†åˆ†æ¡¶è¿‡äºç²—ç³™

```python
def _rating_to_bucket(rating: float) -> str:
    bucket = round(rating * 2) / 2  # 0.5 åˆ†ä¸€æ¡£
    return f"{bucket:.1f}"

# é—®é¢˜ï¼š7.0 å’Œ 7.4 è¢«å½’ä¸ºåŒä¸€æ¡£
# ä½† 7.4 å’Œ 7.5 è¢«å½’ä¸ºä¸åŒæ¡£
# è¿™ç§ç¦»æ•£åŒ–ä¼šä¸¢å¤±ä¿¡æ¯
```

#### 2. åºåˆ—é•¿åº¦ä¸ä¸€è‡´

```python
# æœ‰çš„äººæœ‰ 100 éƒ¨ä½œå“ï¼Œæœ‰çš„åªæœ‰ 1 éƒ¨
# å…¨éƒ¨æˆªæ–­/å¡«å……åˆ° 100
# å¡«å……ç”¨ 0ï¼Œä½† 0 åœ¨è®­ç»ƒæ—¶è¢«è¿‡æ»¤
# é‚£äº›åªæœ‰ 1 éƒ¨ä½œå“çš„äººï¼Œæœ‰æ•ˆåºåˆ—é•¿åº¦åªæœ‰ 1
# è¿™ç§åºåˆ—å¯¹ Word2Vec æ¯«æ— æ„ä¹‰
```

---

## ğŸ“ å·¥ç¨‹å®è·µè¯„å®¡

### âœ… ä¼˜ç‚¹

1. æœ‰ `requirements.txt`
2. æœ‰ CLI å…¥å£
3. æœ‰é…ç½®æ–‡ä»¶åˆ†ç¦»

### âŒ ä¸¥é‡é—®é¢˜

#### 1. æµ‹è¯•è¦†ç›–ä¸ºé›¶

```
tests/
â”œâ”€â”€ test_imports.py  # åªæµ‹è¯• import
â””â”€â”€ test_paths.py    # åªæµ‹è¯•è·¯å¾„

# æ ¸å¿ƒé€»è¾‘ 0 æµ‹è¯•
# preprocess? æ²¡æµ‹è¯•
# feature_engineering? æ²¡æµ‹è¯•
# training? æ²¡æµ‹è¯•
```

**æ¯’è¾£ç‚¹è¯„**: æ²¡æœ‰æµ‹è¯•çš„ä»£ç å°±æ˜¯å®šæ—¶ç‚¸å¼¹ã€‚

#### 2. æ²¡æœ‰ CI/CD

```
ç¼ºå¤±ï¼š
â”œâ”€â”€ âŒ GitHub Actions
â”œâ”€â”€ âŒ pre-commit hooks
â”œâ”€â”€ âŒ ä»£ç æ ¼å¼æ£€æŸ¥ (black/ruff)
â””â”€â”€ âŒ ç±»å‹æ£€æŸ¥ (mypy)
```

#### 3. æ–‡æ¡£ç¼ºå¤±

```
README.md: åªæœ‰ 56 è¡Œï¼ŒåŸºæœ¬æ˜¯å ä½ç¬¦
API æ–‡æ¡£: æ— 
æ¶æ„å›¾: æ— 
æ•°æ®æµå›¾: æ— 
```

---

## ğŸ“ˆ æ€§èƒ½è¯„å®¡

### âœ… ä¼˜ç‚¹

1. **æµå¼è®­ç»ƒèŠ‚çœå†…å­˜**
```python
# ä» 337 GB é™åˆ° 20 GB
# è¿™æ˜¯æ­£ç¡®çš„ä¼˜åŒ–æ–¹å‘
```

2. **å¹¶è¡Œæ ·æœ¬ç”Ÿæˆ**
```python
with mp.Pool(n_workers) as pool:
    results = pool.imap_unordered(...)
```

### âŒ é—®é¢˜

#### 1. GPU åˆ©ç”¨ç‡ä½

```python
# å¤§é‡æ—¶é—´èŠ±åœ¨ CPU ä¸Šï¼š
# - pandas å¤„ç†
# - æ ·æœ¬ç”Ÿæˆ
# - è´Ÿé‡‡æ ·

# GPU åªåœ¨ model.fit() æ—¶å·¥ä½œ
# å…¸å‹çš„ CPU ç“¶é¢ˆ
```

#### 2. I/O ç“¶é¢ˆ

```python
# æ¯ä¸ª epoch é‡æ–°ä»ç£ç›˜åŠ è½½ chunk
# åº”è¯¥ç”¨ tf.data.TFRecordDataset æˆ– prefetch
```

---

## ğŸ¯ æ”¹è¿›å»ºè®®

### ä¼˜å…ˆçº§ P0ï¼ˆå¿…é¡»åšï¼‰

1. **å®šä¹‰æ¸…æ™°çš„é¡¹ç›®ç›®æ ‡**
   - å¦‚æœæ˜¯"æ¨èç³»ç»Ÿ"ï¼šè¡¥å…¨å¬å›å±‚ã€ç²¾æ’å±‚
   - å¦‚æœæ˜¯"åµŒå…¥è®­ç»ƒ"ï¼šæ”¹åï¼Œä¸è¦è¯¯å¯¼

2. **æ·»åŠ å•å…ƒæµ‹è¯•**
   ```bash
   pytest tests/ --cov=imdb_word2vec --cov-report=html
   # ç›®æ ‡è¦†ç›–ç‡ > 70%
   ```

3. **åˆ é™¤æˆ–æ•´åˆ Autoencoder**
   - è¦ä¹ˆä¸ Word2Vec è”åˆè®­ç»ƒ
   - è¦ä¹ˆåˆ é™¤è¿™ä¸ªå­¤å„¿æ¨¡å—

### ä¼˜å…ˆçº§ P1ï¼ˆåº”è¯¥åšï¼‰

4. **ä¼˜åŒ– feature_engineering.py**
   ```python
   # æ›¿æ¢ iterrows
   df.groupby("nconst").apply(lambda x: ...)
   ```

5. **å‡çº§åµŒå…¥æ–¹æ¡ˆ**
   - è€ƒè™‘ GloVe æˆ– FastText
   - æˆ–ç›´æ¥ç”¨é¢„è®­ç»ƒçš„ Sentence-BERT

6. **æ·»åŠ è¯„ä¼°æŒ‡æ ‡**
   - ç›®å‰åªæœ‰ loss å’Œ accuracy
   - æ¨èç³»ç»Ÿéœ€è¦ï¼šRecall@K, NDCG, MAP

### ä¼˜å…ˆçº§ P2ï¼ˆå¯ä»¥åšï¼‰

7. æ·»åŠ  CI/CD
8. æ·»åŠ  API æ–‡æ¡£
9. æ·»åŠ æ¶æ„å›¾

---

## ğŸ“ æ€»ç»“

| é¡¹ç›® | è¯„ä»· |
|------|------|
| **ä½œä¸ºå­¦ä¹ é¡¹ç›®** | â­â­â­â­â˜† ä¸é”™çš„ç»ƒæ‰‹ï¼Œç†è§£äº† Word2Vec åŸç† |
| **ä½œä¸ºæ¯•ä¸šè®¾è®¡** | â­â­â­â˜†â˜† å‹‰å¼ºåŠæ ¼ï¼Œç¼ºä¹åˆ›æ–°å’Œå®Œæ•´æ€§ |
| **ä½œä¸ºç”Ÿäº§ç³»ç»Ÿ** | â­â˜†â˜†â˜†â˜† å®Œå…¨ä¸å¯ç”¨ï¼Œç¼ºå¤±å¤ªå¤šç»„ä»¶ |

**ä¸€å¥è¯æ€»ç»“**: 

> ä½ é€ äº†ä¸€ä¸ªè¿˜ä¸é”™çš„è½®å­ï¼Œä½†è½®å­ä¸æ˜¯æ±½è½¦ã€‚å¦‚æœç›®æ ‡æ˜¯ç”µå½±æ¨èç³»ç»Ÿï¼Œä½ æ‰å®Œæˆäº† 10%ã€‚

# ğŸ“‹ IMDb Word2Vec é¡¹ç›®ä¼˜ç¼ºç‚¹å®Œæ•´æ¸…å•

---

## âœ… ä¼˜ç‚¹æ¸…å•ï¼ˆåº”ä¿ç•™ï¼‰

---

### 1. æµå¼è®­ç»ƒæ¶æ„

**æè¿°**: å°†å¤§è§„æ¨¡æ•°æ®åˆ†å—å¤„ç†ï¼Œæ¯æ¬¡åªåŠ è½½ä¸€éƒ¨åˆ†åˆ°å†…å­˜ï¼Œè®­ç»ƒåé‡Šæ”¾ã€‚

**ä»£ç ç¤ºä¾‹**:
```python
# training.py
for global_epoch in range(global_epochs):
    for chunk_idx in chunk_indices:
        targets, contexts = _load_positive_pairs_from_disk(chunk_path)
        # è®­ç»ƒ
        model.fit(dataset, ...)
        # é‡Šæ”¾å†…å­˜
        del targets, contexts
        gc.collect()
```

**ä¿ç•™ç†ç”±**:
| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **å†…å­˜æ•ˆç‡** | å°† 337 GB æ•°æ®å‹ç¼©åˆ° 20 GB ç£ç›˜ + 6 GB å†…å­˜è¿è¡Œ |
| **å¯æ‰©å±•æ€§** | æ•°æ®é‡å¢é•¿ 10 å€ä¹Ÿèƒ½å¤„ç†ï¼Œåªæ˜¯æ—¶é—´å¢åŠ  |
| **æ–­ç‚¹ç»­è®­** | æ¯ä¸ª chunk ç‹¬ç«‹ï¼Œè®­ç»ƒä¸­æ–­å¯ä»ä¸Šæ¬¡ä½ç½®ç»§ç»­ |
| **å·¥ä¸šå®è·µ** | å¤§å‚è®­ç»ƒå¤§æ¨¡å‹éƒ½é‡‡ç”¨ç±»ä¼¼çš„åˆ†å—ç­–ç•¥ |

**æœªæ¥è¿­ä»£å»ºè®®**: ä¿ç•™å¹¶å¢å¼ºï¼Œæ·»åŠ  checkpoint æœºåˆ¶ä¿å­˜è®­ç»ƒè¿›åº¦ã€‚

---

### 2. é…ç½®é›†ä¸­ç®¡ç†

**æè¿°**: ä½¿ç”¨ dataclass å°†æ‰€æœ‰é…ç½®é¡¹é›†ä¸­åœ¨ `config.py`ï¼Œé¿å…ç¡¬ç¼–ç ã€‚

**ä»£ç ç¤ºä¾‹**:
```python
# config.py
@dataclass
class TrainConfig:
    window_size: int = 5
    num_negative_samples: int = 5
    embedding_dim: int = 128
    # ...

@dataclass  
class Config:
    paths: PathConfig
    data: DataConfig
    train: TrainConfig
```

**ä¿ç•™ç†ç”±**:
| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **å¯ç»´æŠ¤æ€§** | ä¿®æ”¹å‚æ•°åªéœ€æ”¹ä¸€å¤„ï¼Œä¸ç”¨å…¨å±€æœç´¢ |
| **å¯è¯»æ€§** | æ–°äººä¸€çœ‹ config.py å°±çŸ¥é“æœ‰å“ªäº›å¯é…ç½®é¡¹ |
| **ç¯å¢ƒé€‚é…** | å¯è½»æ¾æ‰©å±•ä¸ºä»ç¯å¢ƒå˜é‡æˆ– YAML æ–‡ä»¶åŠ è½½ |
| **ç±»å‹å®‰å…¨** | dataclass æä¾›ç±»å‹æç¤ºï¼ŒIDE å¯ä»¥è‡ªåŠ¨è¡¥å…¨ |

**æœªæ¥è¿­ä»£å»ºè®®**: ä¿ç•™ï¼Œè€ƒè™‘æ”¯æŒä» `config.yaml` åŠ è½½é…ç½®ã€‚

---

### 3. å¤šè®¾å¤‡è‡ªåŠ¨æ£€æµ‹

**æè¿°**: è‡ªåŠ¨æ£€æµ‹ NVIDIA CUDAã€Apple Metalã€CPUï¼Œæ— éœ€ç”¨æˆ·æ‰‹åŠ¨é…ç½®ã€‚

**ä»£ç ç¤ºä¾‹**:
```python
# config.py
def detect_device() -> Tuple[str, str]:
    gpus = tf.config.list_physical_devices("GPU")
    if gpus:
        if "NVIDIA" in device_name.upper():
            return "/GPU:0", "NVIDIA"
        if sys.platform == "darwin":
            return "/GPU:0", "Metal"
    return "/CPU:0", "CPU"
```

**ä¿ç•™ç†ç”±**:
| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **ç”¨æˆ·å‹å¥½** | ç”¨æˆ·ä¸éœ€è¦å…³å¿ƒåº•å±‚ç¡¬ä»¶ |
| **è·¨å¹³å°** | Windows/Linux/macOS éƒ½èƒ½è¿è¡Œ |
| **ä¼˜é›…é™çº§** | æ²¡æœ‰ GPU è‡ªåŠ¨å›é€€åˆ° CPUï¼Œä¸ä¼šæŠ¥é”™ |
| **é›¶é…ç½®** | å³æ’å³ç”¨ï¼Œé™ä½ä½¿ç”¨é—¨æ§› |

**æœªæ¥è¿­ä»£å»ºè®®**: ä¿ç•™ï¼Œæ·»åŠ å¯¹ AMD ROCm çš„æ”¯æŒã€‚

---

### 4. å®ä½“ç±»å‹å‰ç¼€è®¾è®¡

**æè¿°**: ä¸ºä¸åŒç±»å‹çš„å®ä½“æ·»åŠ å‰ç¼€ï¼Œä½¿ Word2Vec èƒ½åŒºåˆ†è¯­ä¹‰ã€‚

**ä»£ç ç¤ºä¾‹**:
```python
# feature_engineering.py
ENTITY_PREFIXES = {
    "movie": "MOV_",    # MOV_tt0111161
    "actor": "ACT_",    # ACT_nm0000151
    "genre": "GEN_",    # GEN_Drama
    "era": "ERA_",      # ERA_1990s
}
```

**ä¿ç•™ç†ç”±**:
| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **è¯­ä¹‰åŒºåˆ†** | "Drama" ä½œä¸ºç±»å‹ vs ä½œä¸ºç”µå½±åï¼Œå‰ç¼€æ˜ç¡®åŒºåˆ† |
| **é¿å…ç¢°æ’** | ä¸åŒç±»å‹çš„ ID å¯èƒ½ç›¸åŒï¼Œå‰ç¼€é¿å…æ··æ·† |
| **å¯è§£é‡Šæ€§** | çœ‹åˆ° `MOV_tt0111161` ç«‹åˆ»çŸ¥é“æ˜¯ç”µå½± |
| **ä¸‹æ¸¸å‹å¥½** | æ¨èç³»ç»Ÿå¯ä»¥æŒ‰å‰ç¼€è¿‡æ»¤å€™é€‰é›† |

**æœªæ¥è¿­ä»£å»ºè®®**: ä¿ç•™ï¼Œä½†éœ€è¦ç»Ÿä¸€åŒä¸€å®ä½“çš„å‰ç¼€ï¼ˆä¸€äººä¸€å‰ç¼€ï¼‰ã€‚

---

### 5. åªå­˜æ­£æ ·æœ¬çš„ä¼˜åŒ–ç­–ç•¥

**æè¿°**: é¢„ç”Ÿæˆé˜¶æ®µåªå­˜å‚¨æ­£æ ·æœ¬å¯¹ï¼Œè´Ÿæ ·æœ¬åœ¨è®­ç»ƒæ—¶åŠ¨æ€é‡‡æ ·ã€‚

**ä»£ç ç¤ºä¾‹**:
```python
# pretraining.py - åªå­˜ 8 bytes/æ ·æœ¬
np.savez_compressed(chunk_path, targets=targets, contexts=contexts)

# training.py - åŠ¨æ€æ·»åŠ è´Ÿæ ·æœ¬
negatives = rng.choice(len(neg_prob), size=(n, num_ns), p=neg_prob)
```

**ä¿ç•™ç†ç”±**:
| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **ç©ºé—´æ•ˆç‡** | ä» 172 bytes/æ ·æœ¬é™åˆ° 8 bytes/æ ·æœ¬ï¼ŒèŠ‚çœ 95% |
| **çµæ´»æ€§** | å¯éšæ—¶è°ƒæ•´è´Ÿæ ·æœ¬æ•°ï¼Œæ— éœ€é‡æ–°ç”Ÿæˆæ•°æ® |
| **éšæœºæ€§** | æ¯ä¸ª epoch ä½¿ç”¨ä¸åŒè´Ÿæ ·æœ¬ï¼Œæ³›åŒ–æ›´å¥½ |
| **ç ”ç©¶è¡¨æ˜** | åŠ¨æ€è´Ÿé‡‡æ ·æ•ˆæœä¸æ¯”é™æ€å·® |

**æœªæ¥è¿­ä»£å»ºè®®**: ä¿ç•™ï¼Œè¿™æ˜¯æ ¸å¿ƒä¼˜åŒ–ã€‚

---

### 6. å¤šç§åºåˆ—ç±»å‹è®¾è®¡

**æè¿°**: è®¾è®¡ 9 ç§ä¸åŒçš„åºåˆ—ç±»å‹ï¼Œæ•è·å¤šç»´åº¦å…³ç³»ã€‚

**ä»£ç ç¤ºä¾‹**:
```python
# feature_engineering.py
all_sequences.extend(_generate_person_movie_sequences(...))    # äºº-ç”µå½±
all_sequences.extend(_generate_movie_context_sequences(...))   # ç”µå½±ä¸Šä¸‹æ–‡
all_sequences.extend(_generate_coactor_sequences(...))         # åˆä½œæ¼”å‘˜
all_sequences.extend(_generate_era_movie_sequences(...))       # åŒå¹´ä»£
all_sequences.extend(_generate_rating_movie_sequences(...))    # åŒè¯„åˆ†
all_sequences.extend(_generate_director_genre_sequences(...))  # å¯¼æ¼”åå¥½
all_sequences.extend(_generate_actor_genre_sequences(...))     # æ¼”å‘˜åå¥½
```

**ä¿ç•™ç†ç”±**:
| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **å…³ç³»ä¸°å¯Œ** | æ•è·äºº-ç‰©ã€ç‰©-ç‰©ã€äºº-äººå¤šç§å…³ç³» |
| **ç‰¹å¾å·¥ç¨‹** | è¿™æ˜¯æ¨èç³»ç»Ÿæœ€æ ¸å¿ƒçš„éƒ¨åˆ† |
| **å¯æ‰©å±•** | å®¹æ˜“æ·»åŠ æ–°çš„åºåˆ—ç±»å‹ |
| **åˆ›æ–°ç‚¹** | å¹´ä»£/è¯„åˆ†åºåˆ—æ˜¯æœ‰ä»·å€¼çš„åˆ›æ–° |

**æœªæ¥è¿­ä»£å»ºè®®**: ä¿ç•™å¹¶æ‰©å±•ï¼Œè€ƒè™‘æ·»åŠ ç”¨æˆ·è¡Œä¸ºåºåˆ—ã€‚

---

### 7. å®Œå–„çš„å¯¼å‡ºæ¨¡å—

**æè¿°**: æ”¯æŒå¤šç§æ ¼å¼å¯¼å‡ºï¼Œä¾¿äºä¸åŒåœºæ™¯ä½¿ç”¨ã€‚

**ä»£ç ç¤ºä¾‹**:
```python
# export.py
export_tsv()           # TensorFlow Projector
export_onnx()          # åœ¨çº¿æ¨ç†
export_json_embeddings()  # ç½‘é¡µå¯è§†åŒ–
export_clustering_visualization()  # t-SNE èšç±»
export_html_visualization()  # äº¤äº’å¼ç½‘é¡µ
export_recommendation_config()  # æ¨èç³»ç»Ÿé…ç½®
```

**ä¿ç•™ç†ç”±**:
| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **éƒ¨ç½²å‹å¥½** | ONNX å¯éƒ¨ç½²åˆ°ä»»ä½•æ¨ç†å¼•æ“ |
| **å¯è§†åŒ–** | HTML å¯ç›´æ¥å±•ç¤ºæˆæœ |
| **è°ƒè¯•æ–¹ä¾¿** | JSON æ ¼å¼ä¾¿äºæ£€æŸ¥å’Œè°ƒè¯• |
| **æ ‡å‡†å…¼å®¹** | TSV å…¼å®¹ TensorFlow Embedding Projector |

**æœªæ¥è¿­ä»£å»ºè®®**: ä¿ç•™ï¼Œè€ƒè™‘æ·»åŠ  TensorRT å¯¼å‡ºã€‚

---

### 8. CLI å‘½ä»¤è¡Œè®¾è®¡

**æè¿°**: æä¾›å®Œæ•´çš„å‘½ä»¤è¡Œæ¥å£ï¼Œæ”¯æŒåˆ†æ­¥æ‰§è¡Œå’Œå®Œæ•´æµç¨‹ã€‚

**ä»£ç ç¤ºä¾‹**:
```bash
python -m imdb_word2vec.cli download
python -m imdb_word2vec.cli preprocess
python -m imdb_word2vec.cli fe
python -m imdb_word2vec.cli pretrain
python -m imdb_word2vec.cli train --use-cache
python -m imdb_word2vec.cli export
python -m imdb_word2vec.cli all  # ä¸€é”®æ‰§è¡Œ
```

**ä¿ç•™ç†ç”±**:
| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **çµæ´»æ€§** | å¯åˆ†æ­¥æ‰§è¡Œï¼Œä¾¿äºè°ƒè¯•å•ä¸ªæ­¥éª¤ |
| **è‡ªåŠ¨åŒ–** | å¯é›†æˆåˆ° shell è„šæœ¬æˆ– CI/CD |
| **ç”¨æˆ·å‹å¥½** | æ¯”ä¿®æ”¹ä»£ç æ›´ç›´è§‚ |
| **å¯ç»„åˆ** | ä¸åŒå‘½ä»¤å¯è‡ªç”±ç»„åˆ |

**æœªæ¥è¿­ä»£å»ºè®®**: ä¿ç•™ï¼Œæ·»åŠ  `--help` çš„ä¸­æ–‡è¯´æ˜ã€‚

---

### 9. æ¨¡å‹å‚æ•°ç»Ÿè®¡åŠŸèƒ½

**æè¿°**: è®­ç»ƒå‰æ‰“å°æ¨¡å‹å‚æ•°é‡å’Œå¤§å°ã€‚

**ä»£ç ç¤ºä¾‹**:
```python
# training.py
def _log_model_stats(model: Word2Vec):
    logger.info("æ€»å‚æ•°é‡: %s (%s)", f"{total:,}", param_str)
    logger.info("æ¨¡å‹å¤§å°: %.2f MB (float32)", stats["model_size_mb"])

# è¾“å‡º:
# æ€»å‚æ•°é‡: 12,800,000 (12.80M)
# æ¨¡å‹å¤§å°: 48.83 MB
```

**ä¿ç•™ç†ç”±**:
| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **é€æ˜åº¦** | ç”¨æˆ·æ¸…æ¥šçŸ¥é“æ¨¡å‹è§„æ¨¡ |
| **å¯¹æ¯”åŸºå‡†** | ä¾¿äºä¸å…¶ä»–æ¨¡å‹å¯¹æ¯” |
| **èµ„æºä¼°ç®—** | å¯æ®æ­¤ä¼°ç®—è®­ç»ƒ/æ¨ç†èµ„æº |
| **ä¸“ä¸šæ€§** | è¿™æ˜¯å¤§æ¨¡å‹æ—¶ä»£çš„æ ‡å‡†åšæ³• |

**æœªæ¥è¿­ä»£å»ºè®®**: ä¿ç•™ï¼Œæ·»åŠ  FLOPs ä¼°ç®—ã€‚

---

### 10. æ—¥å¿—ç³»ç»Ÿè§„èŒƒ

**æè¿°**: ç»Ÿä¸€çš„æ—¥å¿—æ ¼å¼ï¼Œå¸¦æ—¶é—´æˆ³å’Œçº§åˆ«ã€‚

**ä»£ç ç¤ºä¾‹**:
```python
# logging_utils.py
def setup_logging(logs_dir: Path) -> logging.Logger:
    formatter = logging.Formatter(
        "[%(asctime)s][%(levelname)s] %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    # ...

# è¾“å‡º:
# [2025-12-23 17:14:24][INFO] è¯è¡¨è§„æ¨¡: 50000
```

**ä¿ç•™ç†ç”±**:
| æ–¹é¢ | è¯´æ˜ |
|------|------|
| **å¯è¿½æº¯** | æ—¶é—´æˆ³ä¾¿äºå®šä½é—®é¢˜ |
| **ç»Ÿä¸€æ ¼å¼** | æ‰€æœ‰æ¨¡å—æ—¥å¿—é£æ ¼ä¸€è‡´ |
| **æŒä¹…åŒ–** | æ—¥å¿—ä¿å­˜åˆ°æ–‡ä»¶ï¼Œè®­ç»ƒå®Œå¯å›æº¯ |
| **è°ƒè¯•å‹å¥½** | INFO/WARNING/ERROR åˆ†çº§æ¸…æ™° |

**æœªæ¥è¿­ä»£å»ºè®®**: ä¿ç•™ï¼Œè€ƒè™‘æ·»åŠ  JSON æ ¼å¼æ—¥å¿—é€‰é¡¹ã€‚

---

## âŒ ç¼ºç‚¹æ¸…å•ï¼ˆåº”ä¿®å¤ï¼‰

---

### 1. ç›®æ ‡ä¸å®ç°ä¸åŒ¹é…

**é—®é¢˜æè¿°**: é¡¹ç›®å£°ç§°æ˜¯"ç”µå½±æ¨èç³»ç»Ÿ"ï¼Œå®é™…åªå®ç°äº†åµŒå…¥è®­ç»ƒã€‚

**å½±å“**:
```
ç”¨æˆ·æœŸæœ›: è¾“å…¥ç”¨æˆ· ID â†’ è¾“å‡ºæ¨èç”µå½±åˆ—è¡¨
å®é™…èƒ½åš: è¾“å…¥ç”µå½± ID â†’ è¾“å‡ºç›¸ä¼¼ç”µå½±ï¼ˆéœ€è¦é¢å¤–ä»£ç ï¼‰

ç¼ºå¤±ç»„ä»¶:
â”œâ”€â”€ ç”¨æˆ·ç”»åƒ
â”œâ”€â”€ å¬å›å±‚
â”œâ”€â”€ ç²¾æ’å±‚
â”œâ”€â”€ åœ¨çº¿æœåŠ¡
â””â”€â”€ è¯„ä¼°ä½“ç³»
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ A: æ˜ç¡®ç›®æ ‡ï¼Œæ”¹åä¸º "IMDb Embedding Trainer"

# æ–¹æ¡ˆ B: è¡¥å…¨æ¨èç³»ç»Ÿç»„ä»¶
# recommender/
# â”œâ”€â”€ retrieval.py      # å¬å›ï¼šANN æœ€è¿‘é‚»æœç´¢
# â”œâ”€â”€ ranking.py        # ç²¾æ’ï¼šCTR é¢„ä¼°æ¨¡å‹
# â”œâ”€â”€ serving.py        # åœ¨çº¿æœåŠ¡ API
# â””â”€â”€ evaluation.py     # ç¦»çº¿è¯„ä¼° (Recall@K, NDCG)
```

**ä¿®å¤ä¼˜å…ˆçº§**: ğŸ”´ P0ï¼ˆå¿…é¡»ï¼‰

---

### 2. æµ‹è¯•è¦†ç›–ä¸ºé›¶

**é—®é¢˜æè¿°**: `tests/` ç›®å½•åªæœ‰ import æµ‹è¯•å’Œè·¯å¾„æµ‹è¯•ï¼Œæ ¸å¿ƒé€»è¾‘æ— æµ‹è¯•ã€‚

**å½±å“**:
```
é£é™©:
â”œâ”€â”€ é‡æ„æ—¶ä¸çŸ¥é“æ˜¯å¦ç ´åäº†åŠŸèƒ½
â”œâ”€â”€ è¾¹ç•Œæ¡ä»¶æœªéªŒè¯
â”œâ”€â”€ Bug åªèƒ½åœ¨è¿è¡Œæ—¶å‘ç°
â””â”€â”€ ä»£ç è´¨é‡æ— æ³•ä¿è¯
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# tests/test_feature_engineering.py
def test_rating_to_bucket():
    assert _rating_to_bucket(7.3) == "7.5"
    assert _rating_to_bucket(7.2) == "7.0"
    assert _rating_to_bucket("invalid") == "UNKNOWN"

def test_add_prefix():
    assert _add_prefix("tt0111161", "movie") == "MOV_tt0111161"
    assert _add_prefix("\\N", "movie") is None

# tests/test_training.py
def test_add_negative_samples():
    targets = np.array([1, 2, 3])
    contexts = np.array([4, 5, 6])
    # éªŒè¯è¾“å‡ºå½¢çŠ¶ã€ç±»å‹ã€å€¼èŒƒå›´
```

**ä¿®å¤ä¼˜å…ˆçº§**: ğŸ”´ P0ï¼ˆå¿…é¡»ï¼‰

---

### 3. Autoencoder æ¨¡å—å­¤ç«‹

**é—®é¢˜æè¿°**: Autoencoder ä¸ Word2Vec å®Œå…¨ç‹¬ç«‹ï¼Œç”Ÿæˆçš„ç‰¹å¾æ— ä¸‹æ¸¸æ¶ˆè´¹è€…ã€‚

**å½±å“**:
```python
# å½“å‰æ•°æ®æµ:
# feature_engineering â†’ tabular_features.csv â†’ autoencoder â†’ fused_features.parquet â†’ â“

# fused_features.parquet æ²¡äººç”¨ï¼
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ A: åˆ é™¤ Autoencoderï¼ˆå¦‚æœä¸éœ€è¦ï¼‰

# æ–¹æ¡ˆ B: ä¸ Word2Vec è”åˆä½¿ç”¨
def get_item_embedding(item_id):
    w2v_emb = word2vec.get_embedding(item_id)  # 128 ç»´
    ae_emb = autoencoder.get_embedding(item_id)  # 64 ç»´
    return np.concatenate([w2v_emb, ae_emb])  # 192 ç»´

# æ–¹æ¡ˆ C: ç”¨äºç²¾æ’æ¨¡å‹
class RankingModel:
    def __init__(self):
        self.w2v_embeddings = load_word2vec()
        self.ae_features = load_autoencoder()
    
    def predict(self, user_id, item_id):
        features = concat(self.w2v_embeddings[item_id], 
                         self.ae_features[item_id])
        return self.mlp(features)
```

**ä¿®å¤ä¼˜å…ˆçº§**: ğŸŸ¡ P1ï¼ˆé‡è¦ï¼‰

---

### 4. å®ä½“å‰ç¼€ä¸ä¸€è‡´

**é—®é¢˜æè¿°**: åŒä¸€ä¸ªäººå¯èƒ½æœ‰å¤šä¸ªå‰ç¼€ï¼ˆPER_ã€ACT_ã€DIR_ï¼‰ã€‚

**å½±å“**:
```python
# åŒä¸€ä¸ªäºº:
# PER_nm0000151  â† ä½œä¸ºæ™®é€šäººå‘˜
# ACT_nm0000151  â† ä½œä¸ºæ¼”å‘˜å‡ºç°
# DIR_nm0000151  â† ä½œä¸ºå¯¼æ¼”å‡ºç°

# é—®é¢˜: è¿™ä¸‰ä¸ªè¢«è§†ä¸ºä¸åŒå®ä½“ï¼Œä½†å®é™…æ˜¯åŒä¸€ä¸ªäºº
# å¯¼è‡´: åµŒå…¥ç©ºé—´åˆ†è£‚ï¼Œæ— æ³•æ­£ç¡®è®¡ç®—ç›¸ä¼¼åº¦
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ: ç»Ÿä¸€ä½¿ç”¨ PER_ å‰ç¼€ï¼Œç”¨å±æ€§åŒºåˆ†è§’è‰²
ENTITY_PREFIXES = {
    "movie": "MOV_",
    "person": "PER_",   # æ‰€æœ‰äººéƒ½ç”¨è¿™ä¸ª
    "genre": "GEN_",
    "era": "ERA_",
}

# è§’è‰²ä¿¡æ¯æ”¾åˆ°åºåˆ—ä¸Šä¸‹æ–‡ä¸­:
# [PER_nm001, ROLE_actor, MOV_tt001]
# [PER_nm001, ROLE_director, MOV_tt002]
```

**ä¿®å¤ä¼˜å…ˆçº§**: ğŸŸ¡ P1ï¼ˆé‡è¦ï¼‰

---

### 5. feature_engineering.py æ€§èƒ½ä½ä¸‹

**é—®é¢˜æè¿°**: å¤§é‡ä½¿ç”¨ `iterrows()`ï¼Œè¿™æ˜¯ pandas æœ€æ…¢çš„éå†æ–¹å¼ã€‚

**å½±å“**:
```python
# å½“å‰ä»£ç  (æ…¢):
for _, row in tqdm(staff_df.iterrows(), ...):  # O(n) æ…¢
    # å¤„ç†é€»è¾‘

# 21M è¡Œ Ã— å¤šä¸ªå¾ªç¯ = æ•°å°æ—¶
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ A: ä½¿ç”¨ groupby + apply
person_movies = (
    title_principals_df
    .groupby("nconst")["tconst"]
    .apply(list)
    .to_dict()
)

# æ–¹æ¡ˆ B: ä½¿ç”¨å‘é‡åŒ–æ“ä½œ
staff_df["prefixed_tconst"] = "MOV_" + staff_df["tconst"]

# æ–¹æ¡ˆ C: ä½¿ç”¨ polars (æ¯” pandas å¿« 10-100 å€)
import polars as pl
df = pl.read_csv("data.csv")
result = df.groupby("nconst").agg(pl.col("tconst").alias("movies"))
```

**ä¿®å¤ä¼˜å…ˆçº§**: ğŸŸ¡ P1ï¼ˆé‡è¦ï¼‰

---

### 6. ç¼ºä¹è¯„ä¼°æŒ‡æ ‡

**é—®é¢˜æè¿°**: åªæœ‰ loss å’Œ accuracyï¼Œæ— æ¨èç³»ç»Ÿä¸“ç”¨æŒ‡æ ‡ã€‚

**å½±å“**:
```
å½“å‰æŒ‡æ ‡:
â”œâ”€â”€ loss: 3.2451      â† ä¸çŸ¥é“å¥½å
â”œâ”€â”€ accuracy: 0.43    â† ä¸çŸ¥é“å¥½å
â””â”€â”€ positive_recall: 0.56  â† ä¸çŸ¥é“å¥½å

æ— æ³•å›ç­”:
â”œâ”€â”€ æ¨èçš„ç”µå½±ç”¨æˆ·ä¼šå–œæ¬¢å—ï¼Ÿ
â”œâ”€â”€ ç›¸ä¼¼ç”µå½±çœŸçš„ç›¸ä¼¼å—ï¼Ÿ
â””â”€â”€ åµŒå…¥è´¨é‡å¦‚ä½•ï¼Ÿ
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# evaluation.py
def evaluate_embeddings(embeddings, test_pairs):
    """è¯„ä¼°åµŒå…¥è´¨é‡"""
    # 1. ç›¸ä¼¼åº¦ä»»åŠ¡
    hit_rate_10 = calc_hit_rate(embeddings, test_pairs, k=10)
    mrr = calc_mrr(embeddings, test_pairs)
    
    # 2. èšç±»è´¨é‡
    silhouette = calc_silhouette_score(embeddings)
    
    # 3. ä¸‹æ¸¸ä»»åŠ¡
    genre_classification_acc = eval_genre_classification(embeddings)
    
    return {
        "Hit@10": hit_rate_10,
        "MRR": mrr,
        "Silhouette": silhouette,
        "Genre_Acc": genre_classification_acc,
    }
```

**ä¿®å¤ä¼˜å…ˆçº§**: ğŸŸ¡ P1ï¼ˆé‡è¦ï¼‰

---

### 7. å¼‚å¸¸å¤„ç†ç¼ºå¤±

**é—®é¢˜æè¿°**: å…³é”®æ“ä½œç¼ºå°‘ try-exceptï¼Œé”™è¯¯æ—¶ç›´æ¥å´©æºƒã€‚

**å½±å“**:
```python
# å½“å‰ä»£ç :
data = np.load(chunk_path)  # æ–‡ä»¶æŸåï¼Ÿç›´æ¥å´©æºƒ
return data["targets"]       # key ä¸å­˜åœ¨ï¼Ÿç›´æ¥å´©æºƒ

# è®­ç»ƒåˆ°ä¸€åŠå´©æºƒï¼Œæ‰€æœ‰è¿›åº¦ä¸¢å¤±
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
def _load_positive_pairs_from_disk(chunk_path: Path):
    try:
        data = np.load(chunk_path)
        targets = data["targets"]
        contexts = data["contexts"]
        return targets, contexts
    except FileNotFoundError:
        logger.error("æ‰¾ä¸åˆ°æ–‡ä»¶: %s", chunk_path)
        raise
    except KeyError as e:
        logger.error("æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘ key: %s", e)
        raise
    except Exception as e:
        logger.error("åŠ è½½å¤±è´¥: %s, é”™è¯¯: %s", chunk_path, e)
        raise
```

**ä¿®å¤ä¼˜å…ˆçº§**: ğŸŸ  P2ï¼ˆå»ºè®®ï¼‰

---

### 8. é­”æ³•æ•°å­—æ— æ–‡æ¡£

**é—®é¢˜æè¿°**: é…ç½®æ–‡ä»¶ä¸­çš„æ•°å€¼æ²¡æœ‰è§£é‡Šä¸ºä»€ä¹ˆé€‰è¿™ä¸ªå€¼ã€‚

**å½±å“**:
```python
# config.py
subsample_t: float = 1e-4     # ä¸ºä»€ä¹ˆæ˜¯ 1e-4ï¼Ÿ
window_size: int = 5          # ä¸ºä»€ä¹ˆæ˜¯ 5ï¼Ÿ
num_negative_samples: int = 5 # ä¸ºä»€ä¹ˆæ˜¯ 5ï¼Ÿ
embedding_dim: int = 128      # ä¸ºä»€ä¹ˆæ˜¯ 128ï¼Ÿ

# æ–°äººæ¥æ‰‹æ—¶å®Œå…¨ä¸çŸ¥é“èƒ½ä¸èƒ½æ”¹ã€æ”¹äº†ä¼šæ€æ ·
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
@dataclass
class TrainConfig:
    # é«˜é¢‘å­é‡‡æ ·é˜ˆå€¼
    # å‚è€ƒ: Mikolov et al. 2013, æ¨èå€¼ 1e-3 åˆ° 1e-5
    # è¶Šå°è¶Šæ¿€è¿›ï¼Œä¸¢å¼ƒæ›´å¤šé«˜é¢‘è¯
    subsample_t: float = 1e-4
    
    # Skip-gram çª—å£å¤§å°
    # å‚è€ƒ: ä¸€èˆ¬ 5-10ï¼Œçª—å£è¶Šå¤§æ•è·è¶Šè¿œçš„è¯­ä¹‰å…³ç³»
    # ä½†è®¡ç®—é‡ä¹Ÿè¶Šå¤§
    window_size: int = 5
    
    # è´Ÿæ ·æœ¬æ•°é‡
    # å‚è€ƒ: åŸè®ºæ–‡æ¨è 5-20ï¼Œå°æ•°æ®é›†ç”¨ 5-10 è¶³å¤Ÿ
    # å¢åŠ å¯æå‡è´¨é‡ä½†è®­ç»ƒå˜æ…¢
    num_negative_samples: int = 5
```

**ä¿®å¤ä¼˜å…ˆçº§**: ğŸŸ  P2ï¼ˆå»ºè®®ï¼‰

---

### 9. é‡å¤ä»£ç 

**é—®é¢˜æè¿°**: `TqdmProgressCallback` åœ¨ä¸¤ä¸ªæ–‡ä»¶ä¸­é‡å¤å®šä¹‰ã€‚

**å½±å“**:
```python
# training.py ç¬¬ 39-80 è¡Œ
class TqdmProgressCallback(tf.keras.callbacks.Callback):
    # ... 42 è¡Œä»£ç 

# autoencoder.py ç¬¬ 34-55 è¡Œ
class TqdmProgressCallback(tf.keras.callbacks.Callback):
    # ... 22 è¡Œä»£ç 

# é—®é¢˜: æ”¹ä¸€ä¸ªå¿˜äº†æ”¹å¦ä¸€ä¸ªï¼Œè¡Œä¸ºä¸ä¸€è‡´
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# utils.py (æ–°æ–‡ä»¶)
class TqdmProgressCallback(tf.keras.callbacks.Callback):
    """ç»Ÿä¸€çš„è¿›åº¦æ¡å›è°ƒ"""
    # ... å®Œæ•´å®ç°

# training.py
from .utils import TqdmProgressCallback

# autoencoder.py
from .utils import TqdmProgressCallback
```

**ä¿®å¤ä¼˜å…ˆçº§**: ğŸŸ  P2ï¼ˆå»ºè®®ï¼‰

---

### 10. ç¼ºå°‘ CI/CD å’Œä»£ç è´¨é‡æ£€æŸ¥

**é—®é¢˜æè¿°**: æ²¡æœ‰è‡ªåŠ¨åŒ–æµ‹è¯•ã€æ ¼å¼æ£€æŸ¥ã€ç±»å‹æ£€æŸ¥ã€‚

**å½±å“**:
```
é£é™©:
â”œâ”€â”€ PR åˆå¹¶å¯èƒ½å¼•å…¥ bug
â”œâ”€â”€ ä»£ç é£æ ¼ä¸ç»Ÿä¸€
â”œâ”€â”€ ç±»å‹é”™è¯¯åœ¨è¿è¡Œæ—¶æ‰å‘ç°
â””â”€â”€ ä¾èµ–ç‰ˆæœ¬ä¸ä¸€è‡´
```

**ä¿®å¤æ–¹æ¡ˆ**:
```yaml
# .github/workflows/ci.yml
name: CI
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - run: pip install -r requirements.txt
      - run: pip install pytest ruff mypy
      - run: ruff check .          # ä»£ç æ ¼å¼
      - run: mypy imdb_word2vec/   # ç±»å‹æ£€æŸ¥
      - run: pytest tests/ -v      # å•å…ƒæµ‹è¯•
```

```toml
# pyproject.toml
[tool.ruff]
line-length = 100
select = ["E", "F", "W", "I"]

[tool.mypy]
python_version = "3.12"
warn_return_any = true
```

**ä¿®å¤ä¼˜å…ˆçº§**: ğŸŸ  P2ï¼ˆå»ºè®®ï¼‰

---

### 11. Word2Vec ç®—æ³•è¿‡æ—¶

**é—®é¢˜æè¿°**: 2013 å¹´çš„ç®—æ³•ï¼Œæ— æ³•å¤„ç†å¤šä¹‰è¯å’Œ OOVã€‚

**å½±å“**:
```
å±€é™æ€§:
â”œâ”€â”€ "è‹¹æœ" åªæœ‰ä¸€ä¸ªå‘é‡ï¼Œæ— æ³•åŒºåˆ†æ°´æœ/å…¬å¸
â”œâ”€â”€ æ–°ç”µå½±/æ–°æ¼”å‘˜æ— æ³•è·å¾—åµŒå…¥
â”œâ”€â”€ æ— æ³•å¤„ç†é•¿æ–‡æœ¬è¯­ä¹‰
â””â”€â”€ è´¨é‡ä¸å¦‚é¢„è®­ç»ƒæ¨¡å‹
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ A: å‡çº§åˆ° FastText (æ”¯æŒå­è¯)
from gensim.models import FastText
model = FastText(sentences, vector_size=128, window=5)

# æ–¹æ¡ˆ B: ä½¿ç”¨ Sentence-BERT (æ›´å¼ºè¯­ä¹‰)
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = model.encode(["The Shawshank Redemption"])

# æ–¹æ¡ˆ C: ä½¿ç”¨ Two-Tower æ¨¡å‹ (ä¸“ä¸ºæ¨èè®¾è®¡)
# å‚è€ƒ Google çš„ YouTube æ¨èç³»ç»Ÿæ¶æ„
```

**ä¿®å¤ä¼˜å…ˆçº§**: ğŸ”µ P3ï¼ˆé•¿æœŸï¼‰

---

## ğŸ“Š ä¼˜å…ˆçº§æ€»ç»“

| ä¼˜å…ˆçº§ | é¡¹ç›® | é¢„è®¡å·¥æ—¶ |
|--------|------|----------|
| ğŸ”´ P0 | æ˜ç¡®é¡¹ç›®ç›®æ ‡ | 1 å¤© |
| ğŸ”´ P0 | æ·»åŠ å•å…ƒæµ‹è¯• | 3 å¤© |
| ğŸŸ¡ P1 | æ•´åˆ/åˆ é™¤ Autoencoder | 1 å¤© |
| ğŸŸ¡ P1 | ç»Ÿä¸€å®ä½“å‰ç¼€ | 0.5 å¤© |
| ğŸŸ¡ P1 | ä¼˜åŒ– feature_engineering æ€§èƒ½ | 2 å¤© |
| ğŸŸ¡ P1 | æ·»åŠ è¯„ä¼°æŒ‡æ ‡ | 2 å¤© |
| ğŸŸ  P2 | æ·»åŠ å¼‚å¸¸å¤„ç† | 1 å¤© |
| ğŸŸ  P2 | æ–‡æ¡£åŒ–é­”æ³•æ•°å­— | 0.5 å¤© |
| ğŸŸ  P2 | æŠ½å–é‡å¤ä»£ç  | 0.5 å¤© |
| ğŸŸ  P2 | æ·»åŠ  CI/CD | 1 å¤© |
| ğŸ”µ P3 | å‡çº§åµŒå…¥ç®—æ³• | 5 å¤© |

**æ€»è®¡**: çº¦ 17.5 å¤©å·¥ä½œé‡