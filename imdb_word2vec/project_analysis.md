# 项目分析报告：IMDb Word2Vec 向量化与特征融合流水线

## 1. 项目概述

本项目围绕 IMDb 公共数据集（来源：[IMDb Datasets](https://datasets.imdbws.com/)）构建一条端到端的数据处理与表示学习流水线。核心目标是将影片、人员、区域发行和评分等离散信息转化为可计算的向量表示，用于相似度检索、关联挖掘或推荐等下游任务。目标用户包括需要理解影片关联与从业者关系的数据科学从业者、教学与研究人员，以及需要快速验证嵌入效果的工程人员。应用场景涵盖：基于影片标识的相似度分析、基于人员代表作的关系挖掘、按区域或类型维度的影片聚合分析等。项目遵循 IMDb 非商业使用协议，侧重实验与教学复现。

项目背景属于电影内容分析与推荐领域。IMDb 数据集提供结构化的影片元数据、人员元数据、评分和区域别名信息，是电影领域常用的基准数据来源。当前代码以单文件集中式实现，串联了数据下载、清洗、特征构造、自编码融合与 Word2Vec 训练等环节，体现了一个最小可行的端到端样例。项目的发展历程未显式记录版本迭代信息，现有代码对应一次性整合的 all-in-one 脚本。

在数据资产层面，IMDb 提供的六个主要文件包含：

- `title.basics.tsv.gz`：影片基本信息，含唯一标识 `tconst`、标题、类型、年代、时长、成人标记、题材分类等。
- `title.akas.tsv.gz`：影片别名与区域信息，包含 `titleId`、地区、语言、别名类型等字段。
- `title.crew.tsv.gz`：影片剧组信息，包含导演与编剧的人员标识。
- `title.ratings.tsv.gz`：用户评分与投票数，按 `tconst` 聚合。
- `name.basics.tsv.gz`：从业者信息，包含 `nconst`、姓名、出生/死亡年份、职业、代表作列表。
- `title.episode.tsv.gz`：剧集与剧集父标题的映射，现有流程未使用。

项目的总体作用是将这些离散、跨表的标识与属性，经过清洗与融合，输出可直接用于机器学习模型的向量表示，减少下游任务对原始数据解析的重复工作。

## 2. 功能模块梳理

### 2.1 数据下载与持久化

- 输入：IMDb 提供的六个 TSV 压缩文件（`name.basics.tsv.gz`、`title.akas.tsv.gz`、`title.basics.tsv.gz`、`title.crew.tsv.gz`、`title.episode.tsv.gz`、`title.ratings.tsv.gz`）。
- 处理：使用 pandas 读取 TSV（制表符分隔），可选关闭低内存模式以保留字段类型；下载后解压或直接读取压缩格式。
- 输出：将中间结果落盘为 CSV（如影片基本信息、人员信息、区域别名、评分、剧组信息），便于后续重复加载与断点续跑。
- 可靠性：通过缺失值过滤、键集过滤保证跨表关联字段可用；分阶段落盘降低单次内存压力。

### 2.2 数据清洗与筛选

- 影片过滤：仅保留 `titleType=movie` 的记录，删除与当前建模无关的列（`startYear`、`endYear`、`runtimeMinutes`），对 `titleType`、`primaryTitle`、`originalTitle`、`isAdult`、`genres` 的缺失值进行剔除。
- 人员过滤：删除无 `primaryProfession` 或 `knownForTitles` 的记录；通过代表作列与影片键集匹配，确保后续关联有效。
- 区域与别名处理：在 `title.akas.tsv` 中保留 `tconst`、`title`、`region`、`types`，用于后续区域独热与类型独热生成。
- 剧组过滤：在 `title.crew.tsv` 中将导演与编剧字段限定到人员键集，以减少无效关联。

### 2.3 关系构建与特征表生成

- 影片核心表：将影片基本信息与原版标题（`isOriginalTitle=1`）合并，再与评分表（`averageRating`、`numVotes`）合并；对评分与投票数使用中位数填补并转为整数；类型字段拆分为 `genres1`、`genres2`、`genres3`，并保留成人标记。
- 人员特征表：拆分 `primaryProfession` 为三列，拆分代表作为四列；在剧组表中判断导演与编剧身份，为人员表添加 `isDirectors`、`isWriters` 标记；保留人员标识及职业/代表作信息。
- 区域特征表：保留影片标识、别名、区域与类型字段，为区域特征与类型特征生成提供来源。
- 合并关系：通过人员代表作与影片键关联，得到人员-影片的融合表，为后续向量化提供整体特征矩阵。

### 2.4 词汇表构建与向量化

- 词汇注册：对分类特征列（类型、区域、职业、标题、影片标识、人员标识等）随机打乱后逐列注册至词汇表，降低序列性偏差。初始保留 0、1 以便特殊含义（例如填充或保留位）。
- 编码策略：采用字符串到整数的映射，将非整数列统一替换为整数编码；评分与投票数转换为字符串后再编码，保持输入接口一致。
- 结果产物：生成 `vocab.csv`（键到整数的映射）与整数化后的特征表（`final_mapped_vec.csv`），为后续自编码器训练提供输入。

词汇表设计强调去相关与统一接口。随机打乱插入次序减少了因自然排序可能带来的偏置，统一的整数索引使后续的嵌入层可以对所有字段共享相同的访问方式，简化模型端实现。

### 2.5 特征融合（自编码器）

- 输入：整数化后的高维稀疏矩阵，先经标准化处理。
- 模型：多层全连接自编码器，结构为输入 → Dense(512) → Dropout → Dense(256) → Dropout → Dense(128) → Dropout → 输出层（维度与输入一致，ReLU 激活）。
- 训练：使用 MSE 损失与 Adam 优化器，包含早停与模型检查点以保存验证集最佳权重；训练完成后加载最佳权重进行推理。
- 输出：将融合后的稠密特征保存为 Parquet（`fused_features.parquet`），供 Word2Vec 训练使用。

### 2.6 Word2Vec 训练

- 训练数据生成：以融合特征矩阵为“语料”，使用 Skip-gram 窗口生成正样本；借助 TensorFlow 负采样采样器生成负样本，构建目标词与上下文词对。
- 模型结构：定义目标嵌入与上下文嵌入两套权重，使用内积作为打分；损失采用 `CategoricalCrossentropy(from_logits=True)`。
- 训练与导出：训练后导出词向量文件 `vectors.tsv` 与元数据 `metadata.tsv`，便于可视化或相似度查询。

## 3. 技术栈与工具分析

- **编程语言与运行时**：Python 3.12，兼容 TensorFlow 新版本并支持最新语法特性。
- **数据处理**：pandas 负责 TSV 读取、筛选、合并与写入；numpy 负责基础数组运算；pyarrow 用于高效 Parquet 序列化。
- **机器学习与深度学习**：TensorFlow 2.16 提供自编码器与 Skip-gram 模型训练框架；scikit-learn 的 StandardScaler 进行特征标准化。
- **辅助工具**：tqdm 提供迭代进度指示；requests 可用于数据下载；matplotlib 可用于训练过程或向量可视化（在现有脚本中未强制使用）。
- **硬件适配**：TensorFlow 在 GPU 可用时自动调度到 GPU，若无 GPU 则回退 CPU；负采样与小批量机制降低内存占用。
- **文件格式与存储**：中间结果使用 CSV 便于人工查看，最终融合特征使用 Parquet 以提高读写性能并减少存储体积。

## 4. 设计思路解析

- **线性流水线**：代码按数据流程顺序组织，读写与建模步骤依次出现，降低理解门槛；每个阶段的输出作为下阶段输入，减少重复计算。
- **键集过滤**：先构建影片标识集 `movie_tconsts`、人员标识集 `name_nconsts`，再用于跨表过滤，确保关联关系可靠，避免无效行进入后续计算。
- **随机化注册策略**：在词汇表注册阶段对列值进行随机打乱后插入映射，减少潜在的顺序性模式，避免嵌入学习到外在排序信息。
- **数值转字符串再编码**：评分与投票数被转换为字符串并参与统一的词汇映射，使模型端看到的输入全部为整数索引，便于共享嵌入或统一处理。
- **自编码器融合**：通过多层全连接网络对高维离散编码进行压缩与重构，输出的稠密特征可视为跨字段的融合表示，适配下游的词向量训练。
- **负采样 Skip-gram**：采样窗口内生成目标-上下文对，再结合负样本，形成经典 SGNS 训练流程，兼顾计算效率与表示质量。
- **断点与复现**：关键产物（CSV、Parquet、词汇表、模型权重）均落盘，便于重复实验与参数调整；随机种子固定以保证可复现性。

## 5. 框架与架构分析

### 5.1 数据流转

```
IMDb TSV 压缩包
  → TSV 读取与解压
  → 清洗过滤（影片/人员/区域/剧组/评分）
  → 中间 CSV 缓存
  → 影片/人员/区域特征表合并
  → 词汇表注册与整数化（final_mapped_vec.csv）
  → 标准化 + 自编码器训练/推理（fused_features.parquet）
  → Skip-gram 数据生成 + Word2Vec 训练
  → 词向量与元数据导出
```

### 5.2 分层结构（现状）

- **数据层**：负责 TSV 读取、字段裁剪、缺失值处理与 CSV 落盘。
- **特征层**：影片、人员、区域三类特征构造及合并；导演/编剧标记、类型拆分、评分/投票数处理。
- **向量化层**：词汇映射生成与整数化特征表构建。
- **表示学习层**：自编码器训练与融合特征生成。
- **词向量层**：Skip-gram 负采样训练与向量导出。

### 5.3 关键数据结构

- **影片特征表**：`tconst`、标题、三段类型、成人标记、评分、投票数，以及按区域/类型生成的独热列。
- **人员特征表**：`nconst`、三段职业、四个代表作、导演/编剧标记。
- **区域特征表**：影片标识、地区、别名标题、类型字段，为区域独热与类型独热提供来源。
- **融合特征矩阵**：已整数化并标准化的高维矩阵，经自编码器输出稠密表示。
- **词汇映射表**：键到整数的映射，用于编码非数值字段并导出向量元数据。

### 5.4 处理规模与性能考虑

- 数据规模：IMDb 全量包含数千万行记录。现有流程在单机环境下以 pandas 直接读取，适合中等规模内存；需要时可通过行采样或批处理降低内存占用。
- 计算资源：自编码器与 Word2Vec 训练在 GPU 可用时可显著加速；CPU 模式依赖批量大小与负采样数量调节吞吐。
- 中间结果复用：各阶段结果（CSV、Parquet、词汇表）落盘后可用于断点续跑，减少重复计算时间。

### 5.5 参数与可调节项

- 评分/投票填补：使用中位数，保证统计稳健性并减少极值影响。
- 类型拆分：`genres` 按逗号分三列，便于独立编码与后续扩展。
- 负采样参数：窗口大小、负样本数、批大小、嵌入维度可在训练函数参数中调整，以平衡质量与计算开销。
- 词汇表保留项：0、1 预留可用于填充或特殊标签，实际训练时跳过索引 0。
- 自编码器结构：层宽、激活函数、Dropout 比例可调整，用于平衡重构误差与泛化。
- 数据子集：可在读取或训练阶段指定行数或采样比例，适配资源约束。

### 5.6 数据质量与一致性约束

- 评分与投票：`title.ratings.tsv` 以影片为粒度，字段完整性较高，但不同年份的评分分布可能存在偏差，当前流程通过中位数填补保证兼容性。
- 人员代表作：`knownForTitles` 可能包含缺失或与电影集合无交集的条目，现有流程在清洗阶段过滤以保证关联有效性。
- 区域与类型：`title.akas.tsv` 中区域与类型字段有缺失时会转为字符串形式的缺省值，统一进入词汇映射。
- 成人标记：`isAdult` 保留原值，未做额外转换，作为独立分类特征参与编码。

### 5.7 环境与合规

- 许可限制：IMDb 数据仅供非商业用途，当前流程默认在本地读取下载数据，未包含再分发逻辑。
- 硬件兼容：TensorFlow 在 macOS 与 Linux 上均可使用 CPU；GPU 支持依赖用户环境预装相应驱动与 CUDA/Metal 组件，代码层面不强制要求。
- 可重复性：随机种子固定，重要中间结果落盘，降低因随机性导致的结果差异。

### 5.8 特征与局限描述

- 组织形态：当前实现采用单文件集中式结构，功能边界依赖段落和注释分隔，适合线性执行，但模块职责未在目录层面显式呈现。
- 内存模式：默认使用 pandas 全量加载，适合中等内存环境；在超大数据集场景，需要额外的分块或采样策略方可适配。
- 训练耦合：自编码器与 Word2Vec 训练位于同一脚本，便于一次性跑通，但在实验管理与参数调优上需要人工拆分或修改。
- 依赖范围：深度学习部分依赖 TensorFlow，若目标环境更偏向 PyTorch，需重新实现对应训练逻辑；当前代码未提供跨框架适配层。

## 6. 总结

项目呈现了一条从公开 IMDb 数据到向量表示的端到端流水线，包含数据获取、清洗、特征构造、无监督特征融合与 Skip-gram 训练等环节。技术选型以 pandas 和 TensorFlow 为核心，结合随机化词汇注册、数值统一编码、标准化与负采样策略，形成可在 GPU 或 CPU 环境运行的流程。现有形态为单文件顺序实现，便于快速复现与教学演示。项目各步骤均有中间产物，可支撑断点续跑与参数化调优，为后续迭代扩展（如全量数据处理、分布式训练、更多特征引入）提供清晰的起点。
