"""
æ•°æ®è¯¦æƒ…é¡µé¢ (Data Detail)
=========================

å±•ç¤ºå®ä½“çš„å®Œæ•´ä¿¡æ¯ï¼ŒåŒ…æ‹¬åµŒå…¥å‘é‡çš„å¯è§†åŒ–ã€‚

åŠŸèƒ½:
- æœç´¢å¹¶é€‰æ‹©å®ä½“
- æ˜¾ç¤ºå®ä½“è¯¦ç»†ä¿¡æ¯
- 128 ç»´åµŒå…¥å‘é‡çƒ­åŠ›å›¾å¯è§†åŒ–
- å‘é‡ç»Ÿè®¡ä¿¡æ¯

ä½¿ç”¨çš„æ•°æ®æ–‡ä»¶:
- embeddings.json: å®Œæ•´åµŒå…¥æ•°æ®
- recsys/id_to_token.json: ID æ˜ å°„
"""
import streamlit as st
from pathlib import Path
import sys
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from config import AppConfig, ENTITY_TYPE_NAMES, ENTITY_TYPE_COLORS
from utils.data_loader import (
    load_embeddings_json,
    load_token_to_id,
    search_tokens,
    get_entity_type,
)
from utils.visualization import create_vector_heatmap, create_bar_chart
from components.sidebar import render_page_header
from components.entity_card import render_entity_card


# =============================================================================
# é¡µé¢é…ç½®
# =============================================================================

st.set_page_config(
    page_title="Data Detail - " + AppConfig.APP_TITLE,
    page_icon="ğŸ“Š",
    layout=AppConfig.LAYOUT,
)


# =============================================================================
# é¡µé¢æ ‡é¢˜
# =============================================================================

render_page_header(
    title="æ•°æ®è¯¦æƒ…",
    description="æŸ¥çœ‹å®ä½“çš„å®Œæ•´ä¿¡æ¯å’Œ 128 ç»´åµŒå…¥å‘é‡å¯è§†åŒ–ã€‚",
    icon="ğŸ“Š",
)


# =============================================================================
# åŠ è½½æ•°æ®
# =============================================================================

@st.cache_data(show_spinner="åŠ è½½åµŒå…¥æ•°æ®...")
def load_data():
    """åŠ è½½åµŒå…¥æ•°æ®"""
    tokens, embeddings, metadata = load_embeddings_json()
    token_to_id = load_token_to_id()
    return tokens, embeddings, metadata, token_to_id


with st.spinner("åŠ è½½æ•°æ®ä¸­..."):
    tokens, embeddings, metadata, token_to_id = load_data()

if len(tokens) == 0:
    st.error("æ— æ³•åŠ è½½åµŒå…¥æ•°æ®ï¼Œè¯·æ£€æŸ¥ embeddings.json æ–‡ä»¶")
    st.stop()


# =============================================================================
# ä¾§è¾¹æ 
# =============================================================================

with st.sidebar:
    st.markdown("### ğŸ“Š æ•°æ®è¯¦æƒ…è®¾ç½®")
    st.markdown("---")
    
    # æ•°æ®ç»Ÿè®¡
    st.markdown("#### ğŸ“ˆ æ•°æ®ç»Ÿè®¡")
    st.metric("è¯æ±‡è¡¨å¤§å°", f"{metadata.get('vocab_size', len(tokens)):,}")
    st.metric("åµŒå…¥ç»´åº¦", metadata.get("embedding_dim", embeddings.shape[1] if len(embeddings) > 0 else 0))
    
    st.markdown("---")
    
    # å®ä½“ç±»å‹ç»Ÿè®¡
    st.markdown("#### ğŸ“Œ å®ä½“ç±»å‹åˆ†å¸ƒ")
    entity_types = metadata.get("entity_types", {})
    for entity_type, count in sorted(entity_types.items(), key=lambda x: -x[1]):
        name = ENTITY_TYPE_NAMES.get(entity_type, entity_type)
        color = ENTITY_TYPE_COLORS.get(entity_type, "#888")
        st.markdown(
            f'<span style="color:{color}">â—</span> {name}: {count:,}',
            unsafe_allow_html=True,
        )


# =============================================================================
# æœç´¢æ¡†
# =============================================================================

st.markdown("## ğŸ” æœç´¢å®ä½“")

search_query = st.text_input(
    "è¾“å…¥ Token åç§°",
    placeholder="ä¾‹å¦‚: MOV_tt0111161, ACT_nm0000001",
    key="detail_search",
)

# æœç´¢ç»“æœ
if search_query and len(search_query) >= 2:
    matches = search_tokens(search_query, limit=10)
    
    if matches:
        st.markdown("**é€‰æ‹©ä¸€ä¸ªå®ä½“:**")
        
        selected = st.selectbox(
            "æœç´¢ç»“æœ",
            options=matches,
            format_func=lambda x: f"{x} ({ENTITY_TYPE_NAMES.get(get_entity_type(x), get_entity_type(x))})",
            key="detail_select",
            label_visibility="collapsed",
        )
        
        if selected:
            st.session_state["detail_token"] = selected
    else:
        st.warning("æœªæ‰¾åˆ°åŒ¹é…çš„ Token")


# =============================================================================
# å®ä½“è¯¦æƒ…å±•ç¤º
# =============================================================================

selected_token = st.session_state.get("detail_token", None)

if selected_token and selected_token in token_to_id:
    st.markdown("---")
    st.markdown(f"## ğŸ“Œ å®ä½“è¯¦æƒ…: `{selected_token}`")
    
    # è·å–åµŒå…¥å‘é‡
    token_id = token_to_id[selected_token]
    
    if token_id < len(embeddings):
        embedding_vec = embeddings[token_id]
        
        # åŸºæœ¬ä¿¡æ¯
        col1, col2 = st.columns([1, 2])
        
        with col1:
            entity_type = get_entity_type(selected_token)
            entity_id = selected_token.split("_", 1)[1] if "_" in selected_token else selected_token
            
            st.markdown("### åŸºæœ¬ä¿¡æ¯")
            
            st.markdown(f"""
            - **Token:** `{selected_token}`
            - **ç±»å‹:** {ENTITY_TYPE_NAMES.get(entity_type, entity_type)} ({entity_type})
            - **ID:** {entity_id}
            - **ç´¢å¼•:** {token_id}
            """)
            
            # å‘é‡ç»Ÿè®¡
            st.markdown("### å‘é‡ç»Ÿè®¡")
            
            stats_col1, stats_col2 = st.columns(2)
            with stats_col1:
                st.metric("ç»´åº¦", len(embedding_vec))
                st.metric("æœ€å°å€¼", f"{np.min(embedding_vec):.4f}")
                st.metric("æœ€å¤§å€¼", f"{np.max(embedding_vec):.4f}")
            with stats_col2:
                st.metric("å‡å€¼", f"{np.mean(embedding_vec):.4f}")
                st.metric("æ ‡å‡†å·®", f"{np.std(embedding_vec):.4f}")
                st.metric("L2 èŒƒæ•°", f"{np.linalg.norm(embedding_vec):.4f}")
        
        with col2:
            # å‘é‡çƒ­åŠ›å›¾
            st.markdown("### åµŒå…¥å‘é‡å¯è§†åŒ–")
            
            fig = create_vector_heatmap(
                embedding_vec,
                title="",
                height=200,
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # å‘é‡å€¼åˆ†å¸ƒç›´æ–¹å›¾
            st.markdown("### å‘é‡å€¼åˆ†å¸ƒ")
            
            import plotly.express as px
            
            hist_fig = px.histogram(
                x=embedding_vec,
                nbins=50,
                title="",
                labels={"x": "å‘é‡å€¼", "count": "é¢‘æ¬¡"},
            )
            hist_fig.update_layout(
                height=250,
                paper_bgcolor="rgba(0,0,0,0)",
                plot_bgcolor="rgba(0,0,0,0)",
                font=dict(color="#e0e0e0"),
                xaxis=dict(gridcolor="rgba(255,255,255,0.1)"),
                yaxis=dict(gridcolor="rgba(255,255,255,0.1)"),
            )
            st.plotly_chart(hist_fig, use_container_width=True)
        
        # =============================================================================
        # åŸå§‹å‘é‡æ•°æ®
        # =============================================================================
        
        st.markdown("---")
        st.markdown("### ğŸ“‹ åŸå§‹å‘é‡æ•°æ®")
        
        with st.expander("å±•å¼€æŸ¥çœ‹å®Œæ•´å‘é‡ (128 ç»´)", expanded=False):
            # æ ¼å¼åŒ–æ˜¾ç¤º
            vector_str = ", ".join([f"{v:.6f}" for v in embedding_vec])
            st.code(f"[{vector_str}]", language="python")
            
            # ä¸‹è½½æŒ‰é’®
            import json
            vector_json = json.dumps({
                "token": selected_token,
                "embedding": embedding_vec.tolist(),
            }, indent=2)
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å‘é‡ (JSON)",
                data=vector_json,
                file_name=f"{selected_token}_embedding.json",
                mime="application/json",
            )
    else:
        st.error("è¯¥å®ä½“çš„åµŒå…¥å‘é‡ç´¢å¼•è¶…å‡ºèŒƒå›´")

elif selected_token:
    st.warning(f"æœªæ‰¾åˆ° Token: {selected_token}")

else:
    # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
    st.markdown("---")
    st.markdown("""
    ### ğŸ’¡ ä½¿ç”¨è¯´æ˜
    
    1. åœ¨æœç´¢æ¡†ä¸­è¾“å…¥å®ä½“çš„ Token åç§°
    2. ä»æœç´¢ç»“æœä¸­é€‰æ‹©è¦æŸ¥çœ‹çš„å®ä½“
    3. æŸ¥çœ‹å®ä½“çš„è¯¦ç»†ä¿¡æ¯å’Œå‘é‡å¯è§†åŒ–
    
    ### ğŸ“Š å¯è§†åŒ–è¯´æ˜
    
    - **çƒ­åŠ›å›¾:** å°† 128 ç»´å‘é‡å±•ç¤ºä¸º 4Ã—32 çš„ç½‘æ ¼ï¼Œé¢œè‰²è¡¨ç¤ºå€¼çš„å¤§å°
    - **ç›´æ–¹å›¾:** æ˜¾ç¤ºå‘é‡å€¼çš„åˆ†å¸ƒæƒ…å†µ
    - **ç»Ÿè®¡ä¿¡æ¯:** åŒ…æ‹¬å‡å€¼ã€æ ‡å‡†å·®ã€èŒƒæ•°ç­‰
    """)

    # éšæœºå±•ç¤ºä¸€ä¸ªå®ä½“ä½œä¸ºç¤ºä¾‹
    st.markdown("---")
    st.markdown("### ğŸ² éšæœºç¤ºä¾‹")
    
    if st.button("éšæœºé€‰æ‹©ä¸€ä¸ªå®ä½“"):
        import random
        random_token = random.choice(list(token_to_id.keys()))
        st.session_state["detail_token"] = random_token
        st.rerun()

