"""
åµŒå…¥æ¢ç´¢é¡µé¢ (Embedding Explore)
===============================

æ¢ç´¢åµŒå…¥ç©ºé—´çš„è¯­ä¹‰å…³ç³»ï¼Œæ”¯æŒå‘é‡ç®—æœ¯è¿ç®—ã€‚

åŠŸèƒ½:
- å‘é‡ç®—æœ¯: A - B + C è¿ç®—
- ç±»æ¯”æ¨ç†: King - Man + Woman â‰ˆ Queen
- æœ€è¿‘é‚»æœç´¢

ä½¿ç”¨çš„æ•°æ®æ–‡ä»¶:
- embeddings.npy: åŸå§‹åµŒå…¥å‘é‡
- recsys/token_to_id.json: Token æ˜ å°„
"""
import streamlit as st
from pathlib import Path
import sys
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from config import AppConfig, ENTITY_TYPE_NAMES, ENTITY_TYPE_COLORS
from utils.data_loader import (
    load_embeddings_npy,
    load_token_to_id,
    load_id_to_token,
    search_tokens,
    get_entity_type,
)
from utils.similarity import vector_arithmetic, find_top_k_similar
from utils.visualization import create_vector_heatmap
from components.sidebar import render_page_header
from components.similarity_list import render_similarity_list


# =============================================================================
# é¡µé¢é…ç½®
# =============================================================================

st.set_page_config(
    page_title="Embedding Explore - " + AppConfig.APP_TITLE,
    page_icon="ğŸ”¬",
    layout=AppConfig.LAYOUT,
)


# =============================================================================
# é¡µé¢æ ‡é¢˜
# =============================================================================

render_page_header(
    title="åµŒå…¥æ¢ç´¢",
    description="æ¢ç´¢åµŒå…¥ç©ºé—´çš„è¯­ä¹‰å…³ç³»ï¼Œæ”¯æŒå‘é‡ç®—æœ¯è¿ç®— (A - B + C)ã€‚",
    icon="ğŸ”¬",
)


# =============================================================================
# åŠ è½½æ•°æ®
# =============================================================================

@st.cache_data
def load_data():
    """åŠ è½½æ•°æ®"""
    embeddings = load_embeddings_npy()
    token_to_id = load_token_to_id()
    id_to_token = load_id_to_token()
    return embeddings, token_to_id, id_to_token


embeddings, token_to_id, id_to_token = load_data()

# æ„å»º token åˆ—è¡¨
tokens_list = [""] * len(embeddings)
for token, idx in token_to_id.items():
    if idx < len(tokens_list):
        tokens_list[idx] = token


# =============================================================================
# ä¾§è¾¹æ 
# =============================================================================

with st.sidebar:
    st.markdown("### ğŸ”¬ åµŒå…¥æ¢ç´¢è®¾ç½®")
    st.markdown("---")
    
    st.markdown("#### ğŸ’¡ å‘é‡ç®—æœ¯è¯´æ˜")
    st.markdown("""
    å‘é‡ç®—æœ¯å¯ä»¥æ­ç¤ºåµŒå…¥ç©ºé—´ä¸­çš„è¯­ä¹‰å…³ç³»ã€‚
    
    **ç»å…¸ä¾‹å­:**
    - King - Man + Woman â‰ˆ Queen
    - Paris - France + Italy â‰ˆ Rome
    
    **åœ¨ IMDB æ•°æ®ä¸­:**
    - åŠ¨ä½œç‰‡ - åŠ¨ä½œ + å–œå‰§ â‰ˆ å–œå‰§ç‰‡
    - æ¼”å‘˜A - ç”µå½±A + ç”µå½±B â‰ˆ ç”µå½±Bçš„æ¼”å‘˜
    """)
    
    st.markdown("---")
    
    # ç»“æœæ•°é‡
    result_count = st.slider(
        "ç»“æœæ•°é‡",
        min_value=5,
        max_value=30,
        value=10,
        key="explore_result_count",
    )


# =============================================================================
# å‘é‡ç®—æœ¯ç•Œé¢
# =============================================================================

st.markdown("## â• å‘é‡ç®—æœ¯è¿ç®—")

st.markdown("""
è¾“å…¥è¦è¿›è¡Œè¿ç®—çš„ Tokenï¼Œæ ¼å¼: **æ­£å‘é¡¹ - è´Ÿå‘é¡¹**

ç»“æœå‘é‡ = Î£(æ­£å‘é¡¹) - Î£(è´Ÿå‘é¡¹)
""")

# æ­£å‘é¡¹
st.markdown("### â• æ­£å‘é¡¹ (ç›¸åŠ )")

positive_input = st.text_input(
    "è¾“å…¥æ­£å‘ Token (ç”¨é€—å·åˆ†éš”)",
    placeholder="ä¾‹å¦‚: MOV_tt0111161, GEN_Drama",
    key="positive_input",
)

# è´Ÿå‘é¡¹
st.markdown("### â– è´Ÿå‘é¡¹ (ç›¸å‡)")

negative_input = st.text_input(
    "è¾“å…¥è´Ÿå‘ Token (ç”¨é€—å·åˆ†éš”ï¼Œå¯é€‰)",
    placeholder="ä¾‹å¦‚: GEN_Action",
    key="negative_input",
)

# è§£æè¾“å…¥
def parse_tokens(input_str):
    """è§£æè¾“å…¥çš„ Token å­—ç¬¦ä¸²"""
    if not input_str:
        return []
    tokens = [t.strip() for t in input_str.split(",")]
    return [t for t in tokens if t]

positive_tokens = parse_tokens(positive_input)
negative_tokens = parse_tokens(negative_input)

# éªŒè¯ Token
valid_positive = [t for t in positive_tokens if t in token_to_id]
valid_negative = [t for t in negative_tokens if t in token_to_id]

invalid_tokens = [t for t in positive_tokens + negative_tokens if t not in token_to_id]

if invalid_tokens:
    st.warning(f"ä»¥ä¸‹ Token æœªæ‰¾åˆ°: {', '.join(invalid_tokens)}")

# æ˜¾ç¤ºè§£æç»“æœ
if valid_positive or valid_negative:
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**æ­£å‘é¡¹:**")
        for token in valid_positive:
            entity_type = get_entity_type(token)
            color = ENTITY_TYPE_COLORS.get(entity_type, "#888")
            st.markdown(f'<span style="color:{color}">â—</span> `{token}`', unsafe_allow_html=True)
        if not valid_positive:
            st.caption("(æ— )")
    
    with col2:
        st.markdown("**è´Ÿå‘é¡¹:**")
        for token in valid_negative:
            entity_type = get_entity_type(token)
            color = ENTITY_TYPE_COLORS.get(entity_type, "#888")
            st.markdown(f'<span style="color:{color}">â—</span> `{token}`', unsafe_allow_html=True)
        if not valid_negative:
            st.caption("(æ— )")


# =============================================================================
# è®¡ç®—ç»“æœ
# =============================================================================

if st.button("ğŸ§® è®¡ç®—", use_container_width=True) and valid_positive:
    st.markdown("---")
    st.markdown("## ğŸ“Š è®¡ç®—ç»“æœ")
    
    # æ‰§è¡Œå‘é‡ç®—æœ¯
    result_vec, similar_results = vector_arithmetic(
        embeddings=embeddings,
        tokens=tokens_list,
        token_to_id=token_to_id,
        positive=valid_positive,
        negative=valid_negative,
    )
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.markdown("### ç»“æœå‘é‡")
        
        # å‘é‡çƒ­åŠ›å›¾
        fig = create_vector_heatmap(
            result_vec,
            title="",
            height=150,
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # å‘é‡ç»Ÿè®¡
        st.markdown("**å‘é‡ç»Ÿè®¡:**")
        st.markdown(f"- èŒƒæ•°: {np.linalg.norm(result_vec):.4f}")
        st.markdown(f"- å‡å€¼: {np.mean(result_vec):.4f}")
        st.markdown(f"- æ ‡å‡†å·®: {np.std(result_vec):.4f}")
    
    with col2:
        st.markdown("### æœ€ç›¸ä¼¼çš„å®ä½“")
        
        # æ˜¾ç¤ºç»“æœ
        render_similarity_list(
            results=similar_results[:result_count],
            title="",
            show_rank=True,
        )

elif not valid_positive and (positive_input or negative_input):
    st.info("è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆçš„æ­£å‘ Token")


# =============================================================================
# é¢„è®¾ç¤ºä¾‹
# =============================================================================

st.markdown("---")
st.markdown("## ğŸ¯ é¢„è®¾ç¤ºä¾‹")

st.markdown("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å°è¯•é¢„è®¾çš„å‘é‡è¿ç®—:")

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("**ç±»å‹æ¢ç´¢**")
    if st.button("åŠ¨ä½œ + å–œå‰§", key="example1"):
        st.session_state["positive_input"] = "GEN_Action, GEN_Comedy"
        st.session_state["negative_input"] = ""
        st.rerun()
    
    if st.button("ææ€– - æƒŠæ‚š", key="example2"):
        st.session_state["positive_input"] = "GEN_Horror"
        st.session_state["negative_input"] = "GEN_Thriller"
        st.rerun()

with col2:
    st.markdown("**å¹´ä»£æ¢ç´¢**")
    if st.button("90å¹´ä»£ + åŠ¨ä½œ", key="example3"):
        st.session_state["positive_input"] = "ERA_1990s, GEN_Action"
        st.session_state["negative_input"] = ""
        st.rerun()
    
    if st.button("2020s - 2010s", key="example4"):
        st.session_state["positive_input"] = "ERA_2020s"
        st.session_state["negative_input"] = "ERA_2010s"
        st.rerun()

with col3:
    st.markdown("**è¯„åˆ†æ¢ç´¢**")
    if st.button("é«˜åˆ† (8.5+)", key="example5"):
        st.session_state["positive_input"] = "RAT_8.5, RAT_9.0"
        st.session_state["negative_input"] = ""
        st.rerun()
    
    if st.button("é«˜åˆ† - ä½åˆ†", key="example6"):
        st.session_state["positive_input"] = "RAT_9.0"
        st.session_state["negative_input"] = "RAT_5.0"
        st.rerun()


# =============================================================================
# Token æœç´¢è¾…åŠ©
# =============================================================================

st.markdown("---")
st.markdown("## ğŸ” Token æœç´¢")

search_query = st.text_input(
    "æœç´¢ Token",
    placeholder="è¾“å…¥å…³é”®è¯æœç´¢å¯ç”¨çš„ Token...",
    key="explore_search",
)

if search_query and len(search_query) >= 2:
    matches = search_tokens(search_query, limit=20)
    
    if matches:
        st.markdown(f"**æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…:**")
        
        # åˆ†ç±»æ˜¾ç¤º
        type_groups = {}
        for token in matches:
            entity_type = get_entity_type(token)
            if entity_type not in type_groups:
                type_groups[entity_type] = []
            type_groups[entity_type].append(token)
        
        for entity_type, tokens in type_groups.items():
            name = ENTITY_TYPE_NAMES.get(entity_type, entity_type)
            color = ENTITY_TYPE_COLORS.get(entity_type, "#888")
            
            with st.expander(f"{name} ({len(tokens)} ä¸ª)", expanded=True):
                for token in tokens:
                    st.code(token, language=None)
    else:
        st.info("æœªæ‰¾åˆ°åŒ¹é…çš„ Token")

