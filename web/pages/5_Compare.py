"""
é™ç»´å¯¹æ¯”é¡µé¢ (Dimensionality Reduction Compare)
==============================================

å¯¹æ¯” PCAã€UMAPã€t-SNE ä¸‰ç§é™ç»´æ–¹æ³•çš„æ•ˆæœã€‚

åŠŸèƒ½:
- ä¸‰ç§é™ç»´æ–¹æ³•å¹¶æ’å¯¹æ¯”
- å‚æ•°è°ƒèŠ‚
- é™ç»´ç»“æœå¯è§†åŒ–

ä½¿ç”¨çš„æ•°æ®æ–‡ä»¶:
- embeddings.npy: åŸå§‹åµŒå…¥å‘é‡
"""
import streamlit as st
from pathlib import Path
import sys
import numpy as np
import pandas as pd

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from config import AppConfig, ENTITY_TYPE_NAMES, ENTITY_TYPE_COLORS, DimReductionParams, VizParams
from utils.data_loader import (
    load_embeddings_npy,
    load_token_to_id,
    load_id_to_token,
    get_entity_type,
)
from utils.dimensionality import (
    compute_pca,
    compute_umap,
    compute_tsne,
    sample_embeddings,
    get_cached_reduction,
)
from utils.visualization import create_scatter_plot, create_comparison_plot
from components.sidebar import render_page_header


# =============================================================================
# é¡µé¢é…ç½®
# =============================================================================

st.set_page_config(
    page_title="Compare - " + AppConfig.APP_TITLE,
    page_icon="ğŸ“ˆ",
    layout=AppConfig.LAYOUT,
)


# =============================================================================
# é¡µé¢æ ‡é¢˜
# =============================================================================

render_page_header(
    title="é™ç»´å¯¹æ¯”",
    description="å¯¹æ¯” PCAã€UMAPã€t-SNE ä¸‰ç§é™ç»´æ–¹æ³•çš„æ•ˆæœï¼Œè§‚å¯Ÿä¸åŒç®—æ³•å¯¹åµŒå…¥ç©ºé—´çš„æŠ•å½±å·®å¼‚ã€‚",
    icon="ğŸ“ˆ",
)


# =============================================================================
# åŠ è½½æ•°æ®
# =============================================================================

@st.cache_data
def load_data():
    """åŠ è½½æ•°æ®"""
    embeddings = load_embeddings_npy()
    token_to_id = load_token_to_id()
    id_to_token = load_id_to_token()
    return embeddings, token_to_id, id_to_token


embeddings, token_to_id, id_to_token = load_data()


# =============================================================================
# ä¾§è¾¹æ 
# =============================================================================

with st.sidebar:
    st.markdown("### ğŸ“ˆ é™ç»´è®¾ç½®")
    st.markdown("---")
    
    # é‡‡æ ·æ•°é‡
    st.markdown("#### ğŸ“Š é‡‡æ ·è®¾ç½®")
    sample_size = st.slider(
        "é‡‡æ ·æ•°é‡",
        min_value=500,
        max_value=min(10000, len(embeddings)),
        value=min(3000, len(embeddings)),
        step=500,
        help="é™ç»´è®¡ç®—é‡å¤§ï¼Œå»ºè®®ä½¿ç”¨é‡‡æ ·ä»¥åŠ å¿«é€Ÿåº¦",
        key="sample_size",
    )
    
    st.markdown("---")
    
    # t-SNE å‚æ•°
    st.markdown("#### ğŸ”§ t-SNE å‚æ•°")
    tsne_perplexity = st.slider(
        "Perplexity",
        min_value=5,
        max_value=50,
        value=DimReductionParams.TSNE_PERPLEXITY,
        help="å›°æƒ‘åº¦ï¼Œå½±å“å±€éƒ¨ç»“æ„ä¿ç•™ç¨‹åº¦",
        key="tsne_perplexity",
    )
    
    st.markdown("---")
    
    # UMAP å‚æ•°
    st.markdown("#### ğŸ”§ UMAP å‚æ•°")
    umap_n_neighbors = st.slider(
        "n_neighbors",
        min_value=5,
        max_value=50,
        value=DimReductionParams.UMAP_N_NEIGHBORS,
        help="è¿‘é‚»æ•°é‡ï¼Œå½±å“å±€éƒ¨ç»“æ„ä¿ç•™",
        key="umap_n_neighbors",
    )
    
    umap_min_dist = st.slider(
        "min_dist",
        min_value=0.0,
        max_value=1.0,
        value=DimReductionParams.UMAP_MIN_DIST,
        step=0.05,
        help="æœ€å°è·ç¦»ï¼Œå½±å“ç‚¹çš„ç´§å¯†ç¨‹åº¦",
        key="umap_min_dist",
    )
    
    st.markdown("---")
    
    # ç®—æ³•è¯´æ˜
    st.markdown("#### ğŸ“– ç®—æ³•è¯´æ˜")
    
    with st.expander("PCA"):
        st.markdown("""
        **ä¸»æˆåˆ†åˆ†æ (Principal Component Analysis)**
        
        - çº¿æ€§é™ç»´æ–¹æ³•
        - é€Ÿåº¦æœ€å¿«
        - ä¿ç•™å…¨å±€æ–¹å·®æœ€å¤§æ–¹å‘
        - å¯èƒ½ä¸¢å¤±éçº¿æ€§ç»“æ„
        """)
    
    with st.expander("UMAP"):
        st.markdown("""
        **ç»Ÿä¸€æµå½¢è¿‘ä¼¼å’ŒæŠ•å½±**
        
        - éçº¿æ€§é™ç»´æ–¹æ³•
        - é€Ÿåº¦è¾ƒå¿«
        - ä¿ç•™å±€éƒ¨å’Œå…¨å±€ç»“æ„
        - é€‚åˆå¯è§†åŒ–å’Œèšç±»
        """)
    
    with st.expander("t-SNE"):
        st.markdown("""
        **t-åˆ†å¸ƒéšæœºé‚»åŸŸåµŒå…¥**
        
        - éçº¿æ€§é™ç»´æ–¹æ³•
        - é€Ÿåº¦è¾ƒæ…¢
        - æ“…é•¿ä¿ç•™å±€éƒ¨ç»“æ„
        - ç»å…¸å¯è§†åŒ–æ–¹æ³•
        """)


# =============================================================================
# æ•°æ®é‡‡æ ·
# =============================================================================

st.markdown("## ğŸ“Š æ•°æ®å‡†å¤‡")

col1, col2, col3 = st.columns(3)

with col1:
    st.metric("åŸå§‹æ•°æ®é‡", f"{len(embeddings):,}")

with col2:
    st.metric("é‡‡æ ·æ•°é‡", f"{sample_size:,}")

with col3:
    st.metric("åµŒå…¥ç»´åº¦", embeddings.shape[1])

# æ‰§è¡Œé‡‡æ ·
sampled_embeddings, sample_indices = sample_embeddings(
    embeddings, sample_size, random_state=42
)

# è·å–é‡‡æ ·ç‚¹çš„ç±»å‹
sample_types = []
for idx in sample_indices:
    token = id_to_token.get(idx, "")
    entity_type = get_entity_type(token)
    sample_types.append(entity_type)

sample_types = np.array(sample_types)


# =============================================================================
# é™ç»´è®¡ç®—
# =============================================================================

st.markdown("---")
st.markdown("## ğŸ”„ é™ç»´è®¡ç®—")

# è®¡ç®—æŒ‰é’®
if st.button("ğŸš€ å¼€å§‹è®¡ç®—", use_container_width=True):
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    results = {}
    
    # 1. PCA
    status_text.markdown("**æ­£åœ¨è®¡ç®— PCA...**")
    progress_bar.progress(10)
    
    pca_coords = compute_pca(sampled_embeddings)
    results["PCA"] = pca_coords
    
    progress_bar.progress(30)
    
    # 2. UMAP
    status_text.markdown("**æ­£åœ¨è®¡ç®— UMAP... (å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)**")
    
    umap_coords = compute_umap(
        sampled_embeddings,
        n_neighbors=umap_n_neighbors,
        min_dist=umap_min_dist,
    )
    results["UMAP"] = umap_coords
    
    progress_bar.progress(60)
    
    # 3. t-SNE
    status_text.markdown("**æ­£åœ¨è®¡ç®— t-SNE... (å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)**")
    
    tsne_coords = compute_tsne(
        sampled_embeddings,
        perplexity=tsne_perplexity,
    )
    results["t-SNE"] = tsne_coords
    
    progress_bar.progress(100)
    status_text.markdown("**âœ… è®¡ç®—å®Œæˆ!**")
    
    # ä¿å­˜ç»“æœåˆ° session state
    st.session_state["dim_reduction_results"] = results
    st.session_state["dim_reduction_types"] = sample_types
    st.session_state["dim_reduction_indices"] = sample_indices


# =============================================================================
# ç»“æœå±•ç¤º
# =============================================================================

if "dim_reduction_results" in st.session_state:
    results = st.session_state["dim_reduction_results"]
    types = st.session_state["dim_reduction_types"]
    indices = st.session_state["dim_reduction_indices"]
    
    st.markdown("---")
    st.markdown("## ğŸ“Š é™ç»´ç»“æœå¯¹æ¯”")
    
    # å¹¶æ’æ˜¾ç¤ºä¸‰ç§æ–¹æ³•
    col1, col2, col3 = st.columns(3)
    
    for col, (method, coords) in zip([col1, col2, col3], results.items()):
        with col:
            st.markdown(f"### {method}")
            
            # åˆ›å»º DataFrame
            df = pd.DataFrame({
                "x": coords[:, 0],
                "y": coords[:, 1],
                "type": types,
            })
            
            # åˆ›å»ºæ•£ç‚¹å›¾
            fig = create_scatter_plot(
                df,
                x="x",
                y="y",
                color="type",
                height=400,
                show_legend=False,
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # å›¾ä¾‹
    st.markdown("---")
    st.markdown("#### ğŸ“Œ å›¾ä¾‹")
    
    legend_cols = st.columns(len(ENTITY_TYPE_NAMES))
    for col, (entity_type, name) in zip(legend_cols, ENTITY_TYPE_NAMES.items()):
        with col:
            color = ENTITY_TYPE_COLORS.get(entity_type, "#888")
            count = np.sum(types == entity_type)
            st.markdown(
                f'<span style="color:{color}">â—</span> {name} ({count:,})',
                unsafe_allow_html=True,
            )
    
    # =============================================================================
    # æ–¹æ³•å¯¹æ¯”è¡¨æ ¼
    # =============================================================================
    
    st.markdown("---")
    st.markdown("## ğŸ“‹ æ–¹æ³•ç‰¹æ€§å¯¹æ¯”")
    
    comparison_data = {
        "ç‰¹æ€§": ["ç®—æ³•ç±»å‹", "è®¡ç®—é€Ÿåº¦", "å±€éƒ¨ç»“æ„", "å…¨å±€ç»“æ„", "é€‚ç”¨åœºæ™¯"],
        "PCA": ["çº¿æ€§", "âš¡âš¡âš¡ æœ€å¿«", "âŒ è¾ƒå¼±", "âœ… è¾ƒå¥½", "å¿«é€Ÿé¢„è§ˆã€é™å™ª"],
        "UMAP": ["éçº¿æ€§", "âš¡âš¡ è¾ƒå¿«", "âœ… è¾ƒå¥½", "âœ… è¾ƒå¥½", "èšç±»åˆ†æã€å¯è§†åŒ–"],
        "t-SNE": ["éçº¿æ€§", "âš¡ è¾ƒæ…¢", "âœ…âœ… æœ€å¥½", "âŒ è¾ƒå¼±", "å¯è§†åŒ–ã€æ¢ç´¢æ€§åˆ†æ"],
    }
    
    comparison_df = pd.DataFrame(comparison_data)
    
    st.dataframe(
        comparison_df,
        use_container_width=True,
        hide_index=True,
    )

else:
    st.info("ğŸ‘† ç‚¹å‡»ä¸Šæ–¹ã€Œå¼€å§‹è®¡ç®—ã€æŒ‰é’®è¿›è¡Œé™ç»´è®¡ç®—")
    
    # æ˜¾ç¤ºé¢„æœŸæ•ˆæœ
    st.markdown("---")
    st.markdown("### ğŸ’¡ é¢„æœŸæ•ˆæœ")
    
    st.markdown("""
    è®¡ç®—å®Œæˆåï¼Œæ‚¨å°†çœ‹åˆ°:
    
    1. **PCA ç»“æœ**: çº¿æ€§æŠ•å½±ï¼Œä¿ç•™æœ€å¤§æ–¹å·®æ–¹å‘
    2. **UMAP ç»“æœ**: éçº¿æ€§æŠ•å½±ï¼Œä¿ç•™å±€éƒ¨å’Œå…¨å±€ç»“æ„
    3. **t-SNE ç»“æœ**: éçº¿æ€§æŠ•å½±ï¼Œæœ€ä½³å±€éƒ¨ç»“æ„ä¿ç•™
    
    é€šè¿‡å¯¹æ¯”ï¼Œæ‚¨å¯ä»¥:
    - è§‚å¯Ÿä¸åŒç®—æ³•å¯¹èšç±»ç»“æ„çš„å‘ˆç°å·®å¼‚
    - è¯„ä¼°å“ªç§æ–¹æ³•æœ€é€‚åˆæ‚¨çš„åˆ†æéœ€æ±‚
    - äº†è§£å‚æ•°è°ƒæ•´å¯¹ç»“æœçš„å½±å“
    """)

