# 工业级生成式推荐系统架构设计

> 基于 HSTU、OneRec、MTGR 的综合架构方案
> 目标：万亿级数据、低延迟、高并发、多模态、冷启动友好

---

## 一、架构设计原则

### 1.1 核心设计理念

| 原则 | 说明 | 来源 |
|------|------|------|
| **统一表示** | 所有实体（用户、物品、行为）统一为 Token 序列 | HSTU |
| **端到端生成** | 摒弃召回-粗排-精排级联，统一生成框架 | OneRec |
| **特征兼容** | 保留传统 DLRM 特征体系，渐进式迁移 | MTGR |
| **分层解耦** | 离线/近线/在线三层解耦，各司其职 | 工程实践 |

### 1.2 架构目标量化

```
┌─────────────────────────────────────────────────────────────┐
│                    性能目标                                   │
├─────────────────────────────────────────────────────────────┤
│  数据规模    │ 万亿级交互日志 + 百亿级物品库                    │
│  延迟要求    │ P99 < 50ms（端到端推荐响应）                     │
│  并发能力    │ 百万 QPS（峰值）                                │
│  冷启动     │ 新用户/新物品 < 1小时内可推荐                     │
│  多模态     │ 支持商品/视频/文章/音乐等统一推荐                  │
└─────────────────────────────────────────────────────────────┘
```

---

## 二、整体架构总览

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         生成式推荐系统架构                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                        在线服务层 (Online)                           │   │
│  │  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐   │   │
│  │  │ Gateway │→│ Router  │→│ Prefetch│→│Generator│→│ Reranker│   │   │
│  │  │   网关   │  │ 路由分发 │  │ 预取服务 │  │ 生成服务 │  │ 重排服务 │   │   │
│  │  └─────────┘  └─────────┘  └─────────┘  └─────────┘  └─────────┘   │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ↑↓                                       │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                        近线计算层 (Nearline)                          │   │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐               │   │
│  │  │  User State  │  │  Item Index  │  │  Feature     │               │   │
│  │  │  用户状态服务  │  │  物品索引服务  │  │  特征服务    │               │   │
│  │  └──────────────┘  └──────────────┘  └──────────────┘               │   │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐               │   │
│  │  │  Semantic ID │  │  Embedding   │  │  Cold Start  │               │   │
│  │  │  语义ID服务   │  │  向量服务     │  │  冷启动服务   │               │   │
│  │  └──────────────┘  └──────────────┘  └──────────────┘               │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ↑↓                                       │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                        离线训练层 (Offline)                           │   │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐               │   │
│  │  │  Data Lake   │  │  Training    │  │  Evaluation  │               │   │
│  │  │  数据湖      │  │  模型训练     │  │  效果评估     │               │   │
│  │  └──────────────┘  └──────────────┘  └──────────────┘               │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 三、核心模型架构：Unified Generative Transformer (UGT)

### 3.1 模型结构设计

综合 HSTU + OneRec + MTGR 的优势，设计统一生成式 Transformer：

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    Unified Generative Transformer (UGT)                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│                          ┌─────────────────┐                                │
│                          │   Output Head   │                                │
│                          │  (Semantic ID)  │                                │
│                          └────────┬────────┘                                │
│                                   │                                         │
│  ┌────────────────────────────────┴────────────────────────────────────┐   │
│  │                         Decoder (MoE-Enhanced)                       │   │
│  │  ┌─────────────────────────────────────────────────────────────┐    │   │
│  │  │  Layer N: [Causal Attention] → [MoE FFN] → [GLN]            │    │   │
│  │  │  ...                                                        │    │   │
│  │  │  Layer 1: [Causal Attention] → [MoE FFN] → [GLN]            │    │   │
│  │  └─────────────────────────────────────────────────────────────┘    │   │
│  └────────────────────────────────┬────────────────────────────────────┘   │
│                                   │                                         │
│  ┌────────────────────────────────┴────────────────────────────────────┐   │
│  │                         Encoder (Multi-Scale)                        │   │
│  │  ┌─────────────────────────────────────────────────────────────┐    │   │
│  │  │  Long-Term: [Compressed History] ← Lifetime behavior        │    │   │
│  │  │  Short-Term: [Recent Sequence] ← Session behavior           │    │   │
│  │  │  Real-Time: [Current Context] ← Request context             │    │   │
│  │  └─────────────────────────────────────────────────────────────┘    │   │
│  └────────────────────────────────┬────────────────────────────────────┘   │
│                                   │                                         │
│  ┌────────────────────────────────┴────────────────────────────────────┐   │
│  │                     Unified Input Embedding                          │   │
│  │  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐   │   │
│  │  │ Semantic │ │ Position │ │  Type    │ │  Time    │ │ Feature  │   │   │
│  │  │    ID    │ │ Encoding │ │ Encoding │ │ Encoding │ │ Encoding │   │   │
│  │  └──────────┘ └──────────┘ └──────────┘ └──────────┘ └──────────┘   │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 3.2 关键技术组件

#### 3.2.1 语义 ID 系统 (Semantic ID)

**来源**: TIGER + OneRec

```python
class SemanticIDEncoder:
    """
    多模态协同语义 ID 编码器
    
    将任意物品编码为层次化语义 ID 序列：
    - Level 1: 粗粒度类目 (1024 codes)
    - Level 2: 细粒度属性 (4096 codes)  
    - Level 3: 实例区分 (16384 codes)
    
    示例：
    电影《肖申克的救赎》→ [C_drama, A_classic, I_tt0111161]
    商品 iPhone 15      → [C_electronics, A_phone, I_sku123456]
    """
    
    def __init__(self, config):
        # 多模态编码器
        self.text_encoder = TextEncoder()      # 文本特征
        self.image_encoder = ImageEncoder()    # 图像特征
        self.video_encoder = VideoEncoder()    # 视频特征
        self.collab_encoder = CollabEncoder()  # 协同特征
        
        # RQ-VAE 量化器 (残差量化)
        self.quantizer = ResidualVectorQuantizer(
            num_codebooks=3,           # 3层语义ID
            codebook_sizes=[1024, 4096, 16384],
            embedding_dim=256,
        )
    
    def encode(self, item) -> List[int]:
        """将物品编码为语义ID序列"""
        # 1. 多模态特征融合
        features = self.fuse_multimodal(item)
        
        # 2. 残差量化生成语义ID
        semantic_ids, _ = self.quantizer(features)
        
        return semantic_ids
```

#### 3.2.2 点积聚合注意力 (Dot-Product Aggregated Attention)

**来源**: HSTU

```python
class DotProductAggregatedAttention(nn.Module):
    """
    HSTU 的核心注意力机制
    
    优势：
    1. 替代 softmax，避免归一化导致的信息损失
    2. 更适合非平稳词汇表（推荐场景的物品分布）
    3. 支持高效的 M-FALCON 加速
    """
    
    def __init__(self, d_model, n_heads):
        super().__init__()
        self.d_model = d_model
        self.n_heads = n_heads
        self.head_dim = d_model // n_heads
        
        self.q_proj = nn.Linear(d_model, d_model)
        self.k_proj = nn.Linear(d_model, d_model)
        self.v_proj = nn.Linear(d_model, d_model)
        self.out_proj = nn.Linear(d_model, d_model)
        
    def forward(self, x, mask=None):
        B, L, D = x.shape
        
        Q = self.q_proj(x).view(B, L, self.n_heads, self.head_dim)
        K = self.k_proj(x).view(B, L, self.n_heads, self.head_dim)
        V = self.v_proj(x).view(B, L, self.n_heads, self.head_dim)
        
        # 点积聚合（不使用 softmax）
        # scores = Q @ K^T / sqrt(d)
        scores = torch.einsum('blhd,bmhd->bhlm', Q, K) / math.sqrt(self.head_dim)
        
        if mask is not None:
            scores = scores.masked_fill(mask == 0, float('-inf'))
        
        # 直接使用 sigmoid 或 ReLU 替代 softmax
        attn_weights = F.relu(scores)  # 或 F.sigmoid(scores)
        
        # 聚合
        out = torch.einsum('bhlm,bmhd->blhd', attn_weights, V)
        out = out.reshape(B, L, D)
        
        return self.out_proj(out)
```

#### 3.2.3 Group Layer Normalization (GLN)

**来源**: MTGR

```python
class GroupLayerNorm(nn.Module):
    """
    分组层归一化
    
    针对不同语义空间的 Token 使用不同的归一化参数：
    - 用户行为 Token
    - 物品属性 Token  
    - 上下文 Token
    - 交叉特征 Token
    """
    
    def __init__(self, d_model, num_groups=4):
        super().__init__()
        self.num_groups = num_groups
        self.norms = nn.ModuleList([
            nn.LayerNorm(d_model) for _ in range(num_groups)
        ])
    
    def forward(self, x, token_types):
        """
        x: (B, L, D) 输入张量
        token_types: (B, L) Token 类型标识
        """
        output = torch.zeros_like(x)
        
        for group_id in range(self.num_groups):
            mask = (token_types == group_id)
            if mask.any():
                group_tokens = x[mask]
                normalized = self.norms[group_id](group_tokens)
                output[mask] = normalized
        
        return output
```

#### 3.2.4 MoE 增强 FFN

**来源**: OneRec

```python
class MoEFeedForward(nn.Module):
    """
    Mixture-of-Experts 前馈网络
    
    不同类型的推荐任务激活不同的专家：
    - Expert 1-4: 视频推荐专家
    - Expert 5-8: 商品推荐专家
    - Expert 9-12: 文章推荐专家
    - Expert 13-16: 通用专家
    """
    
    def __init__(self, d_model, d_ff, num_experts=16, top_k=4):
        super().__init__()
        self.num_experts = num_experts
        self.top_k = top_k
        
        # 专家网络
        self.experts = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d_model, d_ff),
                nn.GELU(),
                nn.Linear(d_ff, d_model),
            ) for _ in range(num_experts)
        ])
        
        # 门控网络
        self.gate = nn.Linear(d_model, num_experts)
    
    def forward(self, x):
        B, L, D = x.shape
        
        # 计算门控权重
        gate_logits = self.gate(x)  # (B, L, num_experts)
        gate_weights, selected_experts = torch.topk(
            F.softmax(gate_logits, dim=-1), 
            self.top_k, 
            dim=-1
        )
        
        # 稀疏激活专家
        output = torch.zeros_like(x)
        for i, expert in enumerate(self.experts):
            mask = (selected_experts == i).any(dim=-1)
            if mask.any():
                expert_out = expert(x[mask])
                weight = gate_weights[mask][..., (selected_experts[mask] == i).nonzero()[-1]]
                output[mask] += expert_out * weight
        
        return output
```

---

## 四、数据流与统一表示

### 4.1 事件序列化 (Event Tokenization)

**来源**: HSTU

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        统一事件序列表示                                       │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  原始数据:                                                                   │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ User123 在 2025-01-03 10:30 观看了电影《肖申克的救赎》完整版，评分 5 星  │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                        ↓                                    │
│  Token 序列:                                                                │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ [USER_123] [TIME_2025010310] [ACTION_VIEW] [DURATION_FULL]          │   │
│  │ [ITEM_MOV_tt0111161] [SEMANTIC_C_drama] [SEMANTIC_A_classic]        │   │
│  │ [RATING_5] [CONTEXT_mobile] [CONTEXT_home]                          │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│  Token 类型分组:                                                            │
│  ┌───────────────┬───────────────┬───────────────┬───────────────┐        │
│  │   用户 Token   │   行为 Token   │   物品 Token   │   上下文 Token │        │
│  │   (Group 0)   │   (Group 1)   │   (Group 2)   │   (Group 3)   │        │
│  └───────────────┴───────────────┴───────────────┴───────────────┘        │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 4.2 多模态物品表示

```python
class MultiModalItemEncoder:
    """
    统一多模态物品编码器
    
    支持: 商品、视频、文章、音乐、电影等
    """
    
    MODALITY_CONFIGS = {
        "product": {
            "text": ["title", "description", "brand"],
            "image": ["main_image", "gallery"],
            "structured": ["category", "price", "sales"],
        },
        "video": {
            "text": ["title", "tags"],
            "image": ["cover", "keyframes"],
            "video": ["clip_embedding"],
            "audio": ["audio_embedding"],
        },
        "article": {
            "text": ["title", "content", "abstract"],
            "image": ["illustrations"],
        },
        "movie": {
            "text": ["title", "plot", "genres"],
            "image": ["poster"],
            "structured": ["year", "rating", "cast"],
        },
    }
    
    def encode(self, item, item_type: str) -> torch.Tensor:
        """统一编码接口"""
        config = self.MODALITY_CONFIGS[item_type]
        
        embeddings = []
        
        # 文本模态
        if "text" in config:
            text_emb = self.text_encoder(item, config["text"])
            embeddings.append(text_emb)
        
        # 图像模态
        if "image" in config:
            image_emb = self.image_encoder(item, config["image"])
            embeddings.append(image_emb)
        
        # 视频模态
        if "video" in config:
            video_emb = self.video_encoder(item, config["video"])
            embeddings.append(video_emb)
        
        # 结构化特征
        if "structured" in config:
            struct_emb = self.struct_encoder(item, config["structured"])
            embeddings.append(struct_emb)
        
        # 融合
        fused = self.fusion_layer(torch.stack(embeddings))
        
        return fused
```

---

## 五、冷启动解决方案

### 5.1 分层冷启动策略

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         冷启动解决方案                                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    Layer 1: 语义先验 (Semantic Prior)                │   │
│  │  ┌─────────────────────────────────────────────────────────────┐    │   │
│  │  │  利用预训练 LLM 的世界知识生成初始表示                          │    │   │
│  │  │  - 新电影: 根据导演、演员、类型生成语义 ID                      │    │   │
│  │  │  - 新商品: 根据类目、品牌、描述生成语义 ID                      │    │   │
│  │  │  - 新用户: 根据注册信息、首次行为生成初始画像                   │    │   │
│  │  └─────────────────────────────────────────────────────────────┘    │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ↓                                        │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    Layer 2: 跨域迁移 (Cross-Domain Transfer)         │   │
│  │  ┌─────────────────────────────────────────────────────────────┐    │   │
│  │  │  利用相似实体的已有表示进行迁移                                │    │   │
│  │  │  - 物品: 基于语义 ID 相似度找到近邻物品                        │    │   │
│  │  │  - 用户: 基于人口统计学特征找到相似用户群                      │    │   │
│  │  └─────────────────────────────────────────────────────────────┘    │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ↓                                        │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    Layer 3: 快速适应 (Rapid Adaptation)              │   │
│  │  ┌─────────────────────────────────────────────────────────────┐    │   │
│  │  │  基于少量交互快速更新表示                                      │    │   │
│  │  │  - 近线更新: 每 5 分钟增量更新用户状态                         │    │   │
│  │  │  - 实时反馈: 点击/跳过信号即时调整推荐                         │    │   │
│  │  └─────────────────────────────────────────────────────────────┘    │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 5.2 LLM 辅助冷启动

```python
class LLMColdStartService:
    """
    基于 LLM 的冷启动服务
    
    利用预训练大模型的世界知识为新实体生成初始表示
    """
    
    def __init__(self, llm_model: str = "qwen3-8b"):
        self.llm = load_llm(llm_model)
        self.semantic_encoder = SemanticIDEncoder()
    
    def generate_item_representation(self, item_metadata: dict) -> dict:
        """
        为新物品生成初始表示
        
        Args:
            item_metadata: 物品元数据（标题、描述、类目等）
        
        Returns:
            包含语义ID、初始向量、相似物品的字典
        """
        # 1. LLM 理解物品
        prompt = f"""
        分析以下物品并提取关键特征：
        标题: {item_metadata['title']}
        描述: {item_metadata['description']}
        类目: {item_metadata['category']}
        
        请输出:
        1. 核心卖点 (3-5个关键词)
        2. 目标用户群 (人口统计学特征)
        3. 相似物品类型 (已知类目)
        4. 情感调性 (积极/中性/专业等)
        """
        
        llm_analysis = self.llm.generate(prompt)
        
        # 2. 生成语义 ID
        semantic_id = self.semantic_encoder.encode_from_text(
            item_metadata['title'] + " " + item_metadata['description']
        )
        
        # 3. 找到相似的已有物品
        similar_items = self.find_similar_by_semantic_id(semantic_id, top_k=10)
        
        # 4. 基于相似物品生成初始向量
        if similar_items:
            initial_vector = self.aggregate_similar_vectors(similar_items)
        else:
            initial_vector = self.llm_to_vector(llm_analysis)
        
        return {
            "semantic_id": semantic_id,
            "initial_vector": initial_vector,
            "similar_items": similar_items,
            "llm_analysis": llm_analysis,
        }
```

---

## 六、推理加速与低延迟设计

### 6.1 M-FALCON 加速策略

**来源**: HSTU

```python
class MFalconInference:
    """
    M-FALCON: Masked Falcon 加速推理
    
    核心思想：通过动态掩码策略减少计算量
    - 用户历史序列中，只保留最相关的 K 个行为
    - 候选物品中，分批次逐步过滤
    """
    
    def __init__(self, model, max_history=512, cascade_k=[1000, 100, 10]):
        self.model = model
        self.max_history = max_history
        self.cascade_k = cascade_k  # 级联过滤数量
    
    def inference(self, user_history, candidate_pool):
        """
        加速推理流程
        
        Args:
            user_history: 用户历史行为序列
            candidate_pool: 候选物品池
        
        Returns:
            Top-K 推荐结果
        """
        # 1. 压缩用户历史
        compressed_history = self.compress_history(user_history)
        
        # 2. 级联过滤
        current_candidates = candidate_pool
        
        for k in self.cascade_k:
            # 使用轻量级注意力快速筛选
            scores = self.fast_score(compressed_history, current_candidates)
            top_indices = scores.topk(k).indices
            current_candidates = current_candidates[top_indices]
        
        # 3. 精确打分（只对最终候选）
        final_scores = self.full_score(compressed_history, current_candidates)
        
        return current_candidates, final_scores
    
    def compress_history(self, history):
        """
        压缩用户历史
        
        使用自适应池化将长序列压缩到固定长度
        """
        if len(history) <= self.max_history:
            return history
        
        # 分组聚合：早期行为粗粒度，近期行为细粒度
        early = history[:-self.max_history // 2]
        recent = history[-self.max_history // 2:]
        
        # 早期行为聚合
        early_compressed = self.aggregate_by_time_window(
            early, 
            num_groups=self.max_history // 4
        )
        
        return torch.cat([early_compressed, recent])
```

### 6.2 GPU 优化策略

**来源**: MTGR

```python
class GPUOptimizedService:
    """
    GPU 优化推理服务
    
    关键优化:
    1. H2D (Host to Device) 数据传输优化
    2. CUDA Graph 减少 kernel launch 开销
    3. TensorRT 算子融合
    """
    
    def __init__(self, model_path):
        # 加载 TensorRT 优化后的模型
        self.model = load_tensorrt_model(model_path)
        
        # 预热 CUDA Graph
        self.cuda_graphs = {}
        self.warmup_cuda_graphs()
    
    def warmup_cuda_graphs(self):
        """
        预热 CUDA Graph
        
        为常见的 batch size 预先构建计算图
        """
        for batch_size in [1, 8, 16, 32, 64, 128]:
            dummy_input = self.create_dummy_input(batch_size)
            
            # 捕获计算图
            with torch.cuda.graph(self.cuda_graphs.setdefault(batch_size, torch.cuda.CUDAGraph())):
                self.model(dummy_input)
    
    def inference(self, inputs):
        """
        使用 CUDA Graph 加速推理
        """
        batch_size = inputs.shape[0]
        
        # 找到最接近的预热 batch size
        graph_bs = min([bs for bs in self.cuda_graphs if bs >= batch_size], 
                       default=max(self.cuda_graphs.keys()))
        
        # 填充到匹配的 batch size
        padded_inputs = F.pad(inputs, (0, 0, 0, graph_bs - batch_size))
        
        # 使用 CUDA Graph 执行
        self.cuda_graphs[graph_bs].replay()
        
        # 截取有效结果
        return self.model.last_output[:batch_size]
```

### 6.3 延迟分解与优化目标

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         延迟分解 (Target: P99 < 50ms)                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │  阶段                  │   目标延迟   │   优化手段                      │   │
│  ├─────────────────────────────────────────────────────────────────────┤   │
│  │  1. 网络传输           │   < 5ms     │   边缘节点、连接池               │   │
│  │  2. 用户状态获取        │   < 3ms     │   本地缓存、预取                 │   │
│  │  3. 特征拼接           │   < 2ms     │   异步并行、内存优化             │   │
│  │  4. 模型推理           │   < 30ms    │   M-FALCON、CUDA Graph、TRT     │   │
│  │  5. 重排 & 业务规则     │   < 5ms     │   规则引擎、向量化              │   │
│  │  6. 结果序列化         │   < 2ms     │   Protobuf、零拷贝              │   │
│  │  7. 网络返回           │   < 3ms     │   压缩、HTTP/2                  │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│  优化效果对比 (MTGR 实测):                                                   │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │  优化项        │   优化前   │   优化后   │   提升                       │   │
│  ├─────────────────────────────────────────────────────────────────────┤   │
│  │  H2D 传输      │   7.5ms   │   0.012ms │   625x                       │   │
│  │  整体推理      │   19ms    │   12ms    │   37%                        │   │
│  │  吞吐 (QPS)    │   68      │   94      │   38%                        │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 七、高并发与可扩展性设计

### 7.1 分布式服务架构

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         分布式服务架构                                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│                    ┌─────────────────────────────────┐                      │
│                    │         Load Balancer           │                      │
│                    │       (百万 QPS 入口)            │                      │
│                    └───────────────┬─────────────────┘                      │
│                                    │                                        │
│          ┌─────────────────────────┼─────────────────────────┐              │
│          │                         │                         │              │
│          ▼                         ▼                         ▼              │
│  ┌───────────────┐        ┌───────────────┐        ┌───────────────┐       │
│  │  推理集群 A    │        │  推理集群 B    │        │  推理集群 C    │       │
│  │  (视频推荐)    │        │  (商品推荐)    │        │  (内容推荐)    │       │
│  │               │        │               │        │               │       │
│  │ ┌───────────┐ │        │ ┌───────────┐ │        │ ┌───────────┐ │       │
│  │ │ GPU Pod 1 │ │        │ │ GPU Pod 1 │ │        │ │ GPU Pod 1 │ │       │
│  │ │ GPU Pod 2 │ │        │ │ GPU Pod 2 │ │        │ │ GPU Pod 2 │ │       │
│  │ │ ...       │ │        │ │ ...       │ │        │ │ ...       │ │       │
│  │ │ GPU Pod N │ │        │ │ GPU Pod N │ │        │ │ GPU Pod N │ │       │
│  │ └───────────┘ │        │ └───────────┘ │        │ └───────────┘ │       │
│  └───────────────┘        └───────────────┘        └───────────────┘       │
│          │                         │                         │              │
│          └─────────────────────────┼─────────────────────────┘              │
│                                    │                                        │
│                    ┌───────────────▼─────────────────┐                      │
│                    │       Shared Services           │                      │
│                    │  ┌─────────┐ ┌─────────┐        │                      │
│                    │  │ Feature │ │ Index   │        │                      │
│                    │  │ Store   │ │ Service │        │                      │
│                    │  └─────────┘ └─────────┘        │                      │
│                    └─────────────────────────────────┘                      │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 7.2 弹性伸缩策略

```python
class AutoScaler:
    """
    自动弹性伸缩控制器
    
    基于实时流量和延迟动态调整资源
    """
    
    def __init__(self):
        self.metrics = MetricsCollector()
        self.k8s_client = KubernetesClient()
        
        # 伸缩策略
        self.scale_up_threshold = {
            "qps": 0.8,      # QPS 达到容量 80% 时扩容
            "latency_p99": 40,  # P99 延迟超过 40ms 时扩容
            "gpu_util": 0.85,   # GPU 利用率超过 85% 时扩容
        }
        
        self.scale_down_threshold = {
            "qps": 0.3,      # QPS 低于容量 30% 时缩容
            "latency_p99": 20,  # P99 延迟低于 20ms 时缩容
            "gpu_util": 0.4,    # GPU 利用率低于 40% 时缩容
        }
    
    def evaluate_and_scale(self):
        """
        评估当前状态并执行伸缩
        """
        current_metrics = self.metrics.get_current()
        
        # 计算伸缩决策
        scale_factor = self.calculate_scale_factor(current_metrics)
        
        if scale_factor > 1.2:
            # 需要扩容
            self.scale_up(int(scale_factor))
        elif scale_factor < 0.8:
            # 可以缩容
            self.scale_down(int(1 / scale_factor))
```

---

## 八、训练与部署流水线

### 8.1 离线训练架构

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         离线训练流水线                                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                        数据准备阶段                                   │   │
│  │  ┌───────────┐    ┌───────────┐    ┌───────────┐    ┌───────────┐   │   │
│  │  │ 行为日志  │ →  │ 特征提取  │ →  │ 序列构建  │ →  │ 语义ID    │   │   │
│  │  │ (万亿级)  │    │ (Spark)  │    │ (时序)    │    │ (RQ-VAE) │   │   │
│  │  └───────────┘    └───────────┘    └───────────┘    └───────────┘   │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ↓                                        │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                        模型训练阶段                                   │   │
│  │  ┌───────────────────────────────────────────────────────────────┐  │   │
│  │  │           分布式训练集群 (1000+ GPUs)                          │  │   │
│  │  │  ┌─────────────────────────────────────────────────────────┐  │  │   │
│  │  │  │  Stage 1: Semantic ID 预训练 (对比学习)                   │  │  │   │
│  │  │  │  Stage 2: 生成模型预训练 (NTP Loss)                       │  │  │   │
│  │  │  │  Stage 3: 偏好对齐 (RLHF / DPO)                          │  │  │   │
│  │  │  └─────────────────────────────────────────────────────────┘  │  │   │
│  │  └───────────────────────────────────────────────────────────────┘  │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ↓                                        │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                        模型优化阶段                                   │   │
│  │  ┌───────────┐    ┌───────────┐    ┌───────────┐    ┌───────────┐   │   │
│  │  │ 量化压缩  │ →  │ 知识蒸馏  │ →  │ TensorRT │ →  │ 效果验证  │   │   │
│  │  │ (INT8)   │    │ (Teacher  │    │ 编译     │    │ (A/B测试) │   │   │
│  │  │          │    │  →Student)│    │          │    │           │   │   │
│  │  └───────────┘    └───────────┘    └───────────┘    └───────────┘   │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 8.2 训练损失函数

**综合 NTP + 对比学习 + 偏好对齐**

```python
class UnifiedTrainingLoss:
    """
    统一训练损失函数
    
    L_total = L_ntp + λ₁ * L_contrastive + λ₂ * L_preference
    """
    
    def __init__(self, lambda1=0.1, lambda2=0.05):
        self.lambda1 = lambda1
        self.lambda2 = lambda2
    
    def compute(self, model_output, targets, preferences):
        """
        计算总损失
        
        Args:
            model_output: 模型输出 (logits, hidden_states)
            targets: 目标物品序列
            preferences: 偏好对 (chosen, rejected)
        """
        # 1. Next Token Prediction 损失
        logits = model_output.logits
        ntp_loss = F.cross_entropy(
            logits.view(-1, logits.size(-1)),
            targets.view(-1),
            ignore_index=-100,
        )
        
        # 2. 对比学习损失 (语义ID空间)
        embeddings = model_output.hidden_states[-1]
        contrastive_loss = self.compute_contrastive_loss(embeddings)
        
        # 3. 偏好对齐损失 (DPO)
        preference_loss = self.compute_dpo_loss(
            model_output, 
            preferences['chosen'],
            preferences['rejected']
        )
        
        total_loss = (
            ntp_loss + 
            self.lambda1 * contrastive_loss + 
            self.lambda2 * preference_loss
        )
        
        return {
            "total": total_loss,
            "ntp": ntp_loss,
            "contrastive": contrastive_loss,
            "preference": preference_loss,
        }
    
    def compute_dpo_loss(self, model_output, chosen, rejected):
        """
        Direct Preference Optimization 损失
        
        来源: OneRec 的偏好对齐策略
        """
        beta = 0.1  # 温度参数
        
        # 计算 log 概率
        log_prob_chosen = self.compute_log_prob(model_output, chosen)
        log_prob_rejected = self.compute_log_prob(model_output, rejected)
        
        # DPO 损失
        loss = -F.logsigmoid(
            beta * (log_prob_chosen - log_prob_rejected)
        ).mean()
        
        return loss
```

---

## 九、效果评估与监控

### 9.1 评估指标体系

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         评估指标体系                                          │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    离线评估指标                                       │   │
│  │  ┌───────────────┬───────────────┬───────────────┬───────────────┐  │   │
│  │  │   准确性      │    多样性     │    新颖性     │    覆盖率     │  │   │
│  │  ├───────────────┼───────────────┼───────────────┼───────────────┤  │   │
│  │  │ HR@10        │ ILD           │ Novelty       │ Coverage      │  │   │
│  │  │ NDCG@10      │ Category Div  │ Long-tail %   │ Gini Index    │  │   │
│  │  │ MRR          │ Entropy       │               │               │  │   │
│  │  └───────────────┴───────────────┴───────────────┴───────────────┘  │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    在线评估指标                                       │   │
│  │  ┌───────────────┬───────────────┬───────────────┬───────────────┐  │   │
│  │  │   核心业务    │    用户体验   │    系统性能   │    商业价值   │  │   │
│  │  ├───────────────┼───────────────┼───────────────┼───────────────┤  │   │
│  │  │ CTR          │ 观看时长      │ P99 延迟      │ GMV          │  │   │
│  │  │ CVR          │ 留存率        │ QPS          │ RPM          │  │   │
│  │  │ 完播率       │ 回访频次      │ 错误率       │ ROI          │  │   │
│  │  └───────────────┴───────────────┴───────────────┴───────────────┘  │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
│  工业实践参考 (OneRec):                                                      │
│  - 观看时长提升: +1.6%                                                      │
│  - 服务成本降低: 1/10                                                       │
│  - 模型 MFU 提升: 3-5x                                                      │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 十、实施路线图

### 10.1 分阶段实施计划

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         实施路线图                                           │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  Phase 1: 基础建设 (Month 1-3)                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │  □ 搭建多模态 Semantic ID 编码器                                      │   │
│  │  □ 构建统一事件序列化管道                                             │   │
│  │  □ 实现基础 UGT 模型 (单卡训练)                                       │   │
│  │  □ 完成离线评估框架                                                   │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ↓                                        │
│  Phase 2: 模型优化 (Month 4-6)                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │  □ 分布式训练支持 (100+ GPUs)                                         │   │
│  │  □ 实现 MoE 增强解码器                                                │   │
│  │  □ 集成 DPO 偏好对齐                                                  │   │
│  │  □ 冷启动服务开发                                                     │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ↓                                        │
│  Phase 3: 推理加速 (Month 7-9)                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │  □ M-FALCON 加速实现                                                  │   │
│  │  □ TensorRT 模型编译                                                  │   │
│  │  □ CUDA Graph 优化                                                    │   │
│  │  □ H2D 传输优化                                                       │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ↓                                        │
│  Phase 4: 在线部署 (Month 10-12)                                            │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │  □ 小流量 A/B 测试                                                    │   │
│  │  □ 全链路监控建设                                                     │   │
│  │  □ 弹性伸缩配置                                                       │   │
│  │  □ 全量上线                                                           │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 10.2 技术栈选型建议

| 层级 | 组件 | 推荐技术 | 备选方案 |
|------|------|----------|----------|
| **训练框架** | 分布式训练 | DeepSpeed + PyTorch | Megatron-LM |
| **模型格式** | 推理优化 | TensorRT | ONNX Runtime |
| **特征存储** | 在线特征 | Redis Cluster | Apache Ignite |
| **向量检索** | 语义ID检索 | Faiss + GPU | Milvus |
| **消息队列** | 实时特征 | Kafka | Pulsar |
| **容器编排** | 服务部署 | Kubernetes | Ray Serve |
| **监控告警** | 可观测性 | Prometheus + Grafana | DataDog |

---

## 十一、总结

### 核心创新点

1. **统一生成范式**: 融合 HSTU 的事件序列化 + OneRec 的端到端生成 + MTGR 的特征兼容
2. **分层语义 ID**: 多模态协同编码，解决万亿级物品的表示问题
3. **高效推理**: M-FALCON + CUDA Graph + H2D 优化，实现 50ms 以内延迟
4. **冷启动友好**: LLM 辅助语义先验 + 跨域迁移 + 实时适应

### 与传统架构对比

| 维度 | 传统级联架构 | 本方案 (UGT) |
|------|--------------|--------------|
| 架构复杂度 | 召回+粗排+精排+重排 4阶段 | 统一生成框架 |
| 目标一致性 | 各阶段目标不一致 | 端到端优化 |
| 冷启动 | 依赖规则或补充召回 | LLM 语义先验 |
| 多模态 | 各模态独立处理 | 统一 Semantic ID |
| 延迟 | 各阶段累加 | 单次推理 |
| 成本 | 多模型多服务 | 服务成本降至 1/10 |

### 适用场景

- **强烈推荐**: 视频推荐、内容推荐、电商推荐等需要深度个性化的场景
- **谨慎采用**: 对延迟极度敏感（<10ms）的广告投放场景
- **渐进迁移**: 已有成熟推荐系统的企业，建议采用混合架构过渡

