# =============================================================================
# Fluentd 主配置文件
# 
# 日志收集和转发配置，符合 interfaces.yaml 中的日志格式契约
# 支持多种输入源、解析器和输出目标
# =============================================================================

# 系统设置
<system>
  log_level info
  workers 4
  root_dir /var/log/fluentd
  
  # 日志格式
  <log>
    format json
    time_format %Y-%m-%dT%H:%M:%S.%NZ
  </log>
</system>

# =============================================================================
# 输入源配置
# =============================================================================

# Kubernetes 容器日志
<source>
  @type tail
  @id kubernetes-containers
  path /var/log/containers/*.log
  pos_file /var/log/fluentd-containers.log.pos
  tag kubernetes.*
  read_from_head true
  refresh_interval 5
  rotate_wait 5
  enable_stat_watcher false
  
  <parse>
    @type json
    time_key time
    time_format %Y-%m-%dT%H:%M:%S.%NZ
    keep_time_key true
  </parse>
</source>

# 应用日志目录
<source>
  @type tail
  @id application-logs
  path /var/log/apps/**/*.log
  pos_file /var/log/fluentd-apps.log.pos
  tag app.*
  read_from_head true
  refresh_interval 5
  
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%NZ
    keep_time_key true
  </parse>
</source>

# Go 服务日志 (recommend-service, user-service, item-service)
<source>
  @type tail
  @id go-service-logs
  path /var/log/services/**/*.log
  pos_file /var/log/fluentd-services.log.pos
  tag services.*
  read_from_head true
  
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%NZ
  </parse>
</source>

# Python 推理服务日志
<source>
  @type tail
  @id inference-logs
  path /var/log/inference/*.log
  pos_file /var/log/fluentd-inference.log.pos
  tag inference.*
  read_from_head true
  
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%NZ
  </parse>
</source>

# 系统日志
<source>
  @type tail
  @id system-syslog
  path /var/log/syslog
  pos_file /var/log/fluentd-syslog.log.pos
  tag system.syslog
  
  <parse>
    @type syslog
  </parse>
</source>

# Prometheus 指标暴露
<source>
  @type prometheus
  @id prometheus_input
  bind 0.0.0.0
  port 24231
  metrics_path /metrics
</source>

<source>
  @type prometheus_monitor
  @id prometheus_monitor
</source>

<source>
  @type prometheus_output_monitor
  @id prometheus_output_monitor
</source>

# =============================================================================
# 过滤器配置
# =============================================================================

# 添加 Kubernetes 元数据
<filter kubernetes.**>
  @type kubernetes_metadata
  @id filter_kube_metadata
  kubernetes_url https://kubernetes.default.svc
  verify_ssl true
  ca_file /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
  bearer_token_file /var/run/secrets/kubernetes.io/serviceaccount/token
  skip_labels false
  skip_container_metadata false
  skip_master_url false
  skip_namespace_metadata false
  cache_size 1000
  cache_ttl 300
</filter>

# 解析嵌套 JSON 日志
<filter kubernetes.**>
  @type parser
  @id parse_log_field
  key_name log
  reserve_data true
  remove_key_name_field true
  emit_invalid_record_to_error false
  
  <parse>
    @type json
    time_key timestamp
    time_format %Y-%m-%dT%H:%M:%S.%NZ
    keep_time_key true
  </parse>
</filter>

# 添加自定义字段 (符合 interfaces.yaml 契约)
<filter **>
  @type record_transformer
  @id add_required_fields
  enable_ruby true
  
  <record>
    cluster "recommend-prod"
    environment "production"
    fluentd_host "#{Socket.gethostname}"
    # 确保必需字段存在
    timestamp ${record["timestamp"] || time.strftime('%Y-%m-%dT%H:%M:%S.%LZ')}
    level ${record["level"] || "INFO"}
    service ${record["service"] || record.dig("kubernetes", "labels", "app") || "unknown"}
    trace_id ${record["trace_id"] || ""}
    message ${record["message"] || record["log"] || ""}
  </record>
</filter>

# 排除系统命名空间
<filter kubernetes.**>
  @type grep
  <exclude>
    key $.kubernetes.namespace_name
    pattern /^(kube-system|kube-public|kube-node-lease)$/
  </exclude>
</filter>

# 日志级别过滤（生产环境过滤 DEBUG）
<filter **>
  @type grep
  @id filter_debug_logs
  <exclude>
    key level
    pattern /^DEBUG$/
  </exclude>
</filter>

# 敏感信息脱敏
<filter **>
  @type record_transformer
  @id mask_sensitive_data
  enable_ruby true
  
  <record>
    # 脱敏密码字段
    message ${record["message"].to_s.gsub(/password["\s:=]+["']?[^"'\s,}]+["']?/i, 'password=***MASKED***')}
    # 脱敏 token 字段
    message ${record["message"].to_s.gsub(/token["\s:=]+["']?[A-Za-z0-9_\-\.]+["']?/i, 'token=***MASKED***')}
    # 脱敏 API key
    message ${record["message"].to_s.gsub(/api[_\-]?key["\s:=]+["']?[A-Za-z0-9_\-\.]+["']?/i, 'api_key=***MASKED***')}
  </record>
</filter>

# 添加指标标签
<filter **>
  @type prometheus
  @id prometheus_filter
  
  <metric>
    name fluentd_input_records_total
    type counter
    desc Total number of input records
    <labels>
      service ${service}
      level ${level}
    </labels>
  </metric>
</filter>

# =============================================================================
# 输出配置
# =============================================================================

# 输出到 Loki
<match **>
  @type loki
  @id loki_output
  url "http://loki:3100"
  
  # 标签配置 (对应 interfaces.yaml 中的 labels)
  <label>
    app $.kubernetes.labels.app
    namespace $.kubernetes.namespace_name
    pod $.kubernetes.pod_name
    container $.kubernetes.container_name
    level $.level
    service $.service
    env $.environment
  </label>
  
  # 额外标签
  extra_labels {"cluster":"recommend-prod"}
  
  # 行格式
  line_format json
  
  # 缓冲配置
  <buffer>
    @type file
    path /var/log/fluentd-buffers/loki
    flush_mode interval
    flush_interval 5s
    flush_thread_count 4
    flush_at_shutdown true
    retry_type exponential_backoff
    retry_wait 1s
    retry_max_interval 60s
    retry_forever true
    overflow_action block
    chunk_limit_size 8MB
    total_limit_size 2GB
    queued_chunks_limit_size 32
  </buffer>
</match>

# 错误日志单独输出（用于告警）
<match **.ERROR **.FATAL>
  @type copy
  @id error_logs_copy
  
  <store>
    @type loki
    url "http://loki:3100"
    
    <label>
      app $.kubernetes.labels.app
      namespace $.kubernetes.namespace_name
      level $.level
      service $.service
    </label>
    
    <buffer>
      @type file
      path /var/log/fluentd-buffers/loki-errors
      flush_interval 1s
      flush_thread_count 2
    </buffer>
  </store>
  
  # 同时发送到告警 Webhook
  <store>
    @type http
    endpoint http://alertmanager:9093/api/v1/alerts
    content_type application/json
    
    <format>
      @type json
    </format>
    
    <buffer>
      @type memory
      flush_interval 10s
    </buffer>
  </store>
</match>

# 备份到 S3（可选，用于长期存储）
<match backup.**>
  @type s3
  @id s3_backup
  
  aws_key_id "#{ENV['AWS_ACCESS_KEY_ID']}"
  aws_sec_key "#{ENV['AWS_SECRET_ACCESS_KEY']}"
  s3_bucket recommend-logs-backup
  s3_region us-east-1
  
  path logs/%Y/%m/%d/
  s3_object_key_format "%{path}%{time_slice}_%{index}.%{file_extension}"
  
  <buffer time>
    @type file
    path /var/log/fluentd-buffers/s3
    timekey 1h
    timekey_wait 10m
    timekey_use_utc true
    chunk_limit_size 256m
  </buffer>
  
  <format>
    @type json
  </format>
</match>

# 丢弃未匹配的日志（避免内存泄漏）
<match **>
  @type null
  @id null_output
</match>

