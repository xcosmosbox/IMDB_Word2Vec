# Person F: æ€§èƒ½æµ‹è¯•

## ä½ çš„è§’è‰²
ä½ æ˜¯ä¸€å DevOps å·¥ç¨‹å¸ˆï¼Œè´Ÿè´£å®ç°ç”Ÿæˆå¼æ¨èç³»ç»Ÿçš„ **æ€§èƒ½æµ‹è¯•å¥—ä»¶**ï¼ŒåŒ…æ‹¬è´Ÿè½½æµ‹è¯•ã€å‹åŠ›æµ‹è¯•ã€åŸºå‡†æµ‹è¯•å’Œæ€§èƒ½æŠ¥å‘Šã€‚

---

## âš ï¸ é‡è¦ï¼šæ¥å£é©±åŠ¨å¼€å‘

**å¼€å§‹ç¼–ç å‰ï¼Œå¿…é¡»å…ˆé˜…è¯»æ¥å£å®šä¹‰æ–‡ä»¶ï¼š**

```
devops/interfaces.yaml
```

ä½ éœ€è¦å®ç°çš„å¥‘çº¦ï¼š

```yaml
testing:
  load_scenarios:
    - name: baseline
      rps: 100
      duration: 5m
    - name: stress
      rps: 1000
      duration: 10m
  
  sla:
    availability: 99.9%
    p50_latency: 50ms
    p99_latency: 200ms
    error_rate: 0.1%
```

---

## ä½ çš„ä»»åŠ¡

```
devops/testing/
â”œâ”€â”€ load/
â”‚   â”œâ”€â”€ k6/
â”‚   â”‚   â”œâ”€â”€ scenarios/
â”‚   â”‚   â”‚   â”œâ”€â”€ baseline.js
â”‚   â”‚   â”‚   â”œâ”€â”€ stress.js
â”‚   â”‚   â”‚   â””â”€â”€ spike.js
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.js
â”‚   â”‚   â”‚   â””â”€â”€ utils.js
â”‚   â”‚   â””â”€â”€ config.js
â”‚   â”œâ”€â”€ locust/
â”‚   â”‚   â”œâ”€â”€ locustfile.py
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ run-tests.sh
â”œâ”€â”€ benchmark/
â”‚   â”œâ”€â”€ api-benchmark.go
â”‚   â”œâ”€â”€ inference-benchmark.py
â”‚   â””â”€â”€ database-benchmark.sql
â””â”€â”€ reports/
    â”œâ”€â”€ templates/
    â”‚   â””â”€â”€ report.html
    â””â”€â”€ generate-report.py
```

---

## 1. K6 è´Ÿè½½æµ‹è¯• - åŸºçº¿åœºæ™¯ (k6/scenarios/baseline.js)

```javascript
/**
 * åŸºçº¿è´Ÿè½½æµ‹è¯•
 * 
 * ç›®æ ‡: éªŒè¯ç³»ç»Ÿåœ¨æ­£å¸¸è´Ÿè½½ä¸‹çš„æ€§èƒ½
 * RPS: 100
 * æŒç»­æ—¶é—´: 5 åˆ†é’Ÿ
 */

import http from 'k6/http';
import { check, sleep, group } from 'k6';
import { Rate, Trend, Counter } from 'k6/metrics';
import { randomItem, randomIntBetween } from 'https://jslib.k6.io/k6-utils/1.4.0/index.js';

// è‡ªå®šä¹‰æŒ‡æ ‡
const errorRate = new Rate('error_rate');
const recommendLatency = new Trend('recommend_latency');
const searchLatency = new Trend('search_latency');
const feedbackCounter = new Counter('feedback_count');

// é…ç½®
const BASE_URL = __ENV.BASE_URL || 'http://localhost:8080';
const API_KEY = __ENV.API_KEY || 'test-api-key';

// æµ‹è¯•æ•°æ®
const USER_IDS = Array.from({ length: 1000 }, (_, i) => `user_${i}`);
const ITEM_IDS = Array.from({ length: 10000 }, (_, i) => `item_${i}`);
const SEARCH_TERMS = ['action', 'comedy', 'drama', 'sci-fi', 'horror', 'romance'];

// è´Ÿè½½é…ç½®
export const options = {
  scenarios: {
    baseline: {
      executor: 'constant-arrival-rate',
      rate: 100,           // 100 RPS
      timeUnit: '1s',
      duration: '5m',
      preAllocatedVUs: 50,
      maxVUs: 200,
    },
  },
  thresholds: {
    http_req_failed: ['rate<0.01'],      // é”™è¯¯ç‡ < 1%
    http_req_duration: ['p(95)<500'],     // P95 < 500ms
    'recommend_latency': ['p(99)<200'],   // æ¨è P99 < 200ms
    'search_latency': ['p(99)<300'],      // æœç´¢ P99 < 300ms
    'error_rate': ['rate<0.001'],         // è‡ªå®šä¹‰é”™è¯¯ç‡ < 0.1%
  },
};

// å…¬å…±è¯·æ±‚å¤´
const headers = {
  'Content-Type': 'application/json',
  'Authorization': `Bearer ${API_KEY}`,
};

// ä¸»æµ‹è¯•å‡½æ•°
export default function () {
  // éšæœºé€‰æ‹©æµ‹è¯•åœºæ™¯
  const scenario = randomItem(['recommend', 'search', 'feedback', 'detail']);
  
  switch (scenario) {
    case 'recommend':
      testRecommendations();
      break;
    case 'search':
      testSearch();
      break;
    case 'feedback':
      testFeedback();
      break;
    case 'detail':
      testItemDetail();
      break;
  }
  
  sleep(randomIntBetween(1, 3));
}

// æµ‹è¯•æ¨èæ¥å£
function testRecommendations() {
  const userId = randomItem(USER_IDS);
  const payload = JSON.stringify({
    user_id: userId,
    limit: 20,
    scene: 'home',
  });
  
  const startTime = Date.now();
  
  const response = http.post(`${BASE_URL}/api/v1/recommend`, payload, { headers });
  
  const duration = Date.now() - startTime;
  recommendLatency.add(duration);
  
  const success = check(response, {
    'recommend status is 200': (r) => r.status === 200,
    'recommend has recommendations': (r) => {
      try {
        const body = JSON.parse(r.body);
        return body.data && body.data.recommendations && body.data.recommendations.length > 0;
      } catch {
        return false;
      }
    },
    'recommend latency < 200ms': () => duration < 200,
  });
  
  errorRate.add(!success);
}

// æµ‹è¯•æœç´¢æ¥å£
function testSearch() {
  const query = randomItem(SEARCH_TERMS);
  const startTime = Date.now();
  
  const response = http.get(`${BASE_URL}/api/v1/items/search?q=${query}&limit=20`, { headers });
  
  const duration = Date.now() - startTime;
  searchLatency.add(duration);
  
  const success = check(response, {
    'search status is 200': (r) => r.status === 200,
    'search has results': (r) => {
      try {
        const body = JSON.parse(r.body);
        return body.data && Array.isArray(body.data);
      } catch {
        return false;
      }
    },
    'search latency < 300ms': () => duration < 300,
  });
  
  errorRate.add(!success);
}

// æµ‹è¯•åé¦ˆæ¥å£
function testFeedback() {
  const payload = JSON.stringify({
    user_id: randomItem(USER_IDS),
    item_id: randomItem(ITEM_IDS),
    action: randomItem(['click', 'view', 'like']),
  });
  
  const response = http.post(`${BASE_URL}/api/v1/feedback`, payload, { headers });
  
  const success = check(response, {
    'feedback status is 200 or 204': (r) => r.status === 200 || r.status === 204,
  });
  
  if (success) {
    feedbackCounter.add(1);
  }
  errorRate.add(!success);
}

// æµ‹è¯•ç‰©å“è¯¦æƒ…æ¥å£
function testItemDetail() {
  const itemId = randomItem(ITEM_IDS);
  
  const response = http.get(`${BASE_URL}/api/v1/items/${itemId}`, { headers });
  
  const success = check(response, {
    'detail status is 200': (r) => r.status === 200,
    'detail has item data': (r) => {
      try {
        const body = JSON.parse(r.body);
        return body.data && body.data.id;
      } catch {
        return false;
      }
    },
  });
  
  errorRate.add(!success);
}

// æµ‹è¯•ç”Ÿå‘½å‘¨æœŸé’©å­
export function setup() {
  console.log('Starting baseline load test...');
  console.log(`Target: ${BASE_URL}`);
  
  // éªŒè¯ç›®æ ‡æœåŠ¡å¯ç”¨
  const healthCheck = http.get(`${BASE_URL}/health`);
  if (healthCheck.status !== 200) {
    throw new Error('Target service is not healthy');
  }
  
  return { startTime: Date.now() };
}

export function teardown(data) {
  const duration = (Date.now() - data.startTime) / 1000;
  console.log(`Test completed in ${duration.toFixed(2)} seconds`);
}
```

---

## 2. K6 å‹åŠ›æµ‹è¯• (k6/scenarios/stress.js)

```javascript
/**
 * å‹åŠ›æµ‹è¯•
 * 
 * ç›®æ ‡: æ‰¾åˆ°ç³»ç»Ÿçš„æ€§èƒ½æé™
 * RPS: é€æ­¥å¢åŠ åˆ° 1000+
 * æŒç»­æ—¶é—´: 10 åˆ†é’Ÿ
 */

import http from 'k6/http';
import { check, sleep } from 'k6';
import { Rate, Trend } from 'k6/metrics';

const errorRate = new Rate('error_rate');
const responseTime = new Trend('response_time');

const BASE_URL = __ENV.BASE_URL || 'http://localhost:8080';

export const options = {
  scenarios: {
    stress: {
      executor: 'ramping-arrival-rate',
      startRate: 50,
      timeUnit: '1s',
      preAllocatedVUs: 100,
      maxVUs: 1000,
      stages: [
        { duration: '1m', target: 100 },   // é¢„çƒ­
        { duration: '2m', target: 300 },   // å¢åŠ è´Ÿè½½
        { duration: '2m', target: 500 },   // ä¸­ç­‰è´Ÿè½½
        { duration: '2m', target: 800 },   // é«˜è´Ÿè½½
        { duration: '2m', target: 1000 },  // å³°å€¼è´Ÿè½½
        { duration: '1m', target: 0 },     // æ¢å¤
      ],
    },
  },
  thresholds: {
    http_req_failed: ['rate<0.05'],        // å…è®¸ 5% é”™è¯¯ç‡
    http_req_duration: ['p(95)<1000'],     // P95 < 1s
    'error_rate': ['rate<0.05'],
  },
};

const headers = {
  'Content-Type': 'application/json',
};

export default function () {
  const userId = `user_${Math.floor(Math.random() * 10000)}`;
  
  const payload = JSON.stringify({
    user_id: userId,
    limit: 20,
    scene: 'home',
  });
  
  const startTime = Date.now();
  const response = http.post(`${BASE_URL}/api/v1/recommend`, payload, { headers });
  const duration = Date.now() - startTime;
  
  responseTime.add(duration);
  
  const success = check(response, {
    'status is 200': (r) => r.status === 200,
  });
  
  errorRate.add(!success);
  
  sleep(0.1);
}

// è‡ªå®šä¹‰æ‘˜è¦æŠ¥å‘Š
export function handleSummary(data) {
  return {
    'stress-test-summary.json': JSON.stringify(data, null, 2),
    stdout: generateTextSummary(data),
  };
}

function generateTextSummary(data) {
  const metrics = data.metrics;
  
  return `
================================================================================
                          STRESS TEST SUMMARY
================================================================================

Duration: ${(data.state.testRunDurationMs / 1000).toFixed(2)}s
VUs Peak: ${data.metrics.vus_max?.values?.max || 'N/A'}

HTTP Requests:
  Total: ${metrics.http_reqs?.values?.count || 0}
  Rate: ${(metrics.http_reqs?.values?.rate || 0).toFixed(2)}/s

Response Time:
  Avg: ${(metrics.http_req_duration?.values?.avg || 0).toFixed(2)}ms
  P50: ${(metrics.http_req_duration?.values['p(50)'] || 0).toFixed(2)}ms
  P90: ${(metrics.http_req_duration?.values['p(90)'] || 0).toFixed(2)}ms
  P95: ${(metrics.http_req_duration?.values['p(95)'] || 0).toFixed(2)}ms
  P99: ${(metrics.http_req_duration?.values['p(99)'] || 0).toFixed(2)}ms
  Max: ${(metrics.http_req_duration?.values?.max || 0).toFixed(2)}ms

Errors:
  Failed Requests: ${metrics.http_req_failed?.values?.passes || 0}
  Error Rate: ${((metrics.error_rate?.values?.rate || 0) * 100).toFixed(4)}%

Thresholds:
${Object.entries(data.metrics)
  .filter(([_, v]) => v.thresholds)
  .map(([name, v]) => {
    const passed = Object.values(v.thresholds).every(t => t.ok);
    return `  ${passed ? 'âœ“' : 'âœ—'} ${name}`;
  })
  .join('\n')}

================================================================================
`;
}
```

---

## 3. Locust è´Ÿè½½æµ‹è¯• (locust/locustfile.py)

```python
"""
Locust è´Ÿè½½æµ‹è¯•è„šæœ¬
æ”¯æŒ Web UI å’Œåˆ†å¸ƒå¼æµ‹è¯•
"""

from locust import HttpUser, task, between, events
from locust.runners import MasterRunner
import random
import json
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RecommendUser(HttpUser):
    """æ¨¡æ‹Ÿæ¨èç³»ç»Ÿç”¨æˆ·"""
    
    wait_time = between(1, 3)  # è¯·æ±‚é—´éš” 1-3 ç§’
    
    def on_start(self):
        """ç”¨æˆ·å¯åŠ¨æ—¶è°ƒç”¨"""
        self.user_id = f"user_{random.randint(1, 100000)}"
        self.headers = {
            "Content-Type": "application/json",
        }
    
    @task(5)  # æƒé‡ 5
    def get_recommendations(self):
        """è·å–æ¨è"""
        payload = {
            "user_id": self.user_id,
            "limit": 20,
            "scene": random.choice(["home", "search", "detail"]),
        }
        
        with self.client.post(
            "/api/v1/recommend",
            json=payload,
            headers=self.headers,
            catch_response=True,
        ) as response:
            if response.status_code == 200:
                data = response.json()
                if data.get("data", {}).get("recommendations"):
                    response.success()
                else:
                    response.failure("No recommendations returned")
            else:
                response.failure(f"Status code: {response.status_code}")
    
    @task(3)  # æƒé‡ 3
    def search_items(self):
        """æœç´¢ç‰©å“"""
        query = random.choice([
            "action", "comedy", "drama", "thriller",
            "sci-fi", "horror", "romance", "documentary"
        ])
        
        with self.client.get(
            f"/api/v1/items/search?q={query}&limit=20",
            headers=self.headers,
            catch_response=True,
        ) as response:
            if response.status_code == 200:
                response.success()
            else:
                response.failure(f"Status code: {response.status_code}")
    
    @task(2)  # æƒé‡ 2
    def submit_feedback(self):
        """æäº¤åé¦ˆ"""
        payload = {
            "user_id": self.user_id,
            "item_id": f"item_{random.randint(1, 10000)}",
            "action": random.choice(["view", "click", "like"]),
        }
        
        with self.client.post(
            "/api/v1/feedback",
            json=payload,
            headers=self.headers,
            catch_response=True,
        ) as response:
            if response.status_code in [200, 204]:
                response.success()
            else:
                response.failure(f"Status code: {response.status_code}")
    
    @task(1)  # æƒé‡ 1
    def get_item_detail(self):
        """è·å–ç‰©å“è¯¦æƒ…"""
        item_id = f"item_{random.randint(1, 10000)}"
        
        with self.client.get(
            f"/api/v1/items/{item_id}",
            headers=self.headers,
            catch_response=True,
        ) as response:
            if response.status_code == 200:
                response.success()
            elif response.status_code == 404:
                # ç‰©å“ä¸å­˜åœ¨æ˜¯æ­£å¸¸çš„
                response.success()
            else:
                response.failure(f"Status code: {response.status_code}")


class AdminUser(HttpUser):
    """æ¨¡æ‹Ÿç®¡ç†å‘˜ç”¨æˆ·ï¼ˆä½é¢‘ï¼‰"""
    
    wait_time = between(5, 10)
    weight = 1  # ä½æƒé‡
    
    @task
    def get_dashboard(self):
        """è·å–ä»ªè¡¨ç›˜æ•°æ®"""
        self.client.get("/api/admin/v1/dashboard")
    
    @task
    def list_users(self):
        """åˆ—å‡ºç”¨æˆ·"""
        self.client.get("/api/admin/v1/users?page=1&page_size=20")


# æµ‹è¯•äº‹ä»¶é’©å­
@events.test_start.add_listener
def on_test_start(environment, **kwargs):
    """æµ‹è¯•å¼€å§‹æ—¶"""
    logger.info("Load test starting...")
    if isinstance(environment.runner, MasterRunner):
        logger.info("Running in distributed mode")


@events.test_stop.add_listener
def on_test_stop(environment, **kwargs):
    """æµ‹è¯•ç»“æŸæ—¶"""
    logger.info("Load test completed")
    
    # æ‰“å°ç»Ÿè®¡æ‘˜è¦
    stats = environment.stats.total
    logger.info(f"Total requests: {stats.num_requests}")
    logger.info(f"Failures: {stats.num_failures}")
    logger.info(f"Avg response time: {stats.avg_response_time:.2f}ms")
    logger.info(f"Requests/s: {stats.total_rps:.2f}")
```

---

## 4. æ€§èƒ½æŠ¥å‘Šç”Ÿæˆå™¨ (reports/generate-report.py)

```python
#!/usr/bin/env python3
"""
æ€§èƒ½æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨
"""

import json
import os
from datetime import datetime
from pathlib import Path
from jinja2 import Template
import argparse


REPORT_TEMPLATE = """
<!DOCTYPE html>
<html>
<head>
    <title>æ€§èƒ½æµ‹è¯•æŠ¥å‘Š - {{ report_time }}</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }
        .container { max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        h1 { color: #333; border-bottom: 2px solid #4CAF50; padding-bottom: 10px; }
        h2 { color: #666; margin-top: 30px; }
        .summary { display: grid; grid-template-columns: repeat(4, 1fr); gap: 20px; margin: 20px 0; }
        .metric-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 8px; text-align: center; }
        .metric-value { font-size: 32px; font-weight: bold; }
        .metric-label { font-size: 14px; opacity: 0.9; margin-top: 5px; }
        table { width: 100%; border-collapse: collapse; margin: 20px 0; }
        th, td { padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }
        th { background: #f8f9fa; }
        .pass { color: #4CAF50; }
        .fail { color: #f44336; }
        .chart { height: 300px; margin: 20px 0; }
        .sla-table td:last-child { font-weight: bold; }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
    <div class="container">
        <h1>ğŸš€ æ€§èƒ½æµ‹è¯•æŠ¥å‘Š</h1>
        <p>ç”Ÿæˆæ—¶é—´: {{ report_time }} | æµ‹è¯•ç±»å‹: {{ test_type }} | æŒç»­æ—¶é—´: {{ duration }}s</p>
        
        <h2>ğŸ“Š æ¦‚è§ˆ</h2>
        <div class="summary">
            <div class="metric-card">
                <div class="metric-value">{{ total_requests | format_number }}</div>
                <div class="metric-label">æ€»è¯·æ±‚æ•°</div>
            </div>
            <div class="metric-card" style="background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);">
                <div class="metric-value">{{ rps | round(2) }}</div>
                <div class="metric-label">RPS</div>
            </div>
            <div class="metric-card" style="background: linear-gradient(135deg, #fc4a1a 0%, #f7b733 100%);">
                <div class="metric-value">{{ avg_latency | round(2) }}ms</div>
                <div class="metric-label">å¹³å‡å»¶è¿Ÿ</div>
            </div>
            <div class="metric-card" style="background: linear-gradient(135deg, #ee0979 0%, #ff6a00 100%);">
                <div class="metric-value">{{ error_rate | round(4) }}%</div>
                <div class="metric-label">é”™è¯¯ç‡</div>
            </div>
        </div>
        
        <h2>â±ï¸ å»¶è¿Ÿåˆ†å¸ƒ</h2>
        <table>
            <tr>
                <th>æŒ‡æ ‡</th>
                <th>å€¼</th>
            </tr>
            <tr><td>P50</td><td>{{ p50 | round(2) }}ms</td></tr>
            <tr><td>P90</td><td>{{ p90 | round(2) }}ms</td></tr>
            <tr><td>P95</td><td>{{ p95 | round(2) }}ms</td></tr>
            <tr><td>P99</td><td>{{ p99 | round(2) }}ms</td></tr>
            <tr><td>Max</td><td>{{ max_latency | round(2) }}ms</td></tr>
        </table>
        
        <h2>ğŸ¯ SLA æ£€æŸ¥</h2>
        <table class="sla-table">
            <tr>
                <th>æŒ‡æ ‡</th>
                <th>ç›®æ ‡</th>
                <th>å®é™…</th>
                <th>çŠ¶æ€</th>
            </tr>
            {% for check in sla_checks %}
            <tr>
                <td>{{ check.name }}</td>
                <td>{{ check.target }}</td>
                <td>{{ check.actual }}</td>
                <td class="{{ 'pass' if check.passed else 'fail' }}">
                    {{ 'âœ“ PASS' if check.passed else 'âœ— FAIL' }}
                </td>
            </tr>
            {% endfor %}
        </table>
        
        <h2>ğŸ“ˆ è¯·æ±‚è¶‹åŠ¿</h2>
        <canvas id="rpsChart" class="chart"></canvas>
        
        <h2>ğŸ“‹ é˜ˆå€¼æ£€æŸ¥</h2>
        <table>
            <tr>
                <th>é˜ˆå€¼</th>
                <th>çŠ¶æ€</th>
            </tr>
            {% for threshold in thresholds %}
            <tr>
                <td>{{ threshold.name }}</td>
                <td class="{{ 'pass' if threshold.passed else 'fail' }}">
                    {{ 'âœ“ PASS' if threshold.passed else 'âœ— FAIL' }}
                </td>
            </tr>
            {% endfor %}
        </table>
    </div>
    
    <script>
        // RPS è¶‹åŠ¿å›¾
        new Chart(document.getElementById('rpsChart'), {
            type: 'line',
            data: {
                labels: {{ rps_trend_labels | tojson }},
                datasets: [{
                    label: 'RPS',
                    data: {{ rps_trend_values | tojson }},
                    borderColor: '#667eea',
                    fill: false,
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
            }
        });
    </script>
</body>
</html>
"""


def format_number(value):
    """æ ¼å¼åŒ–æ•°å­—"""
    return "{:,}".format(int(value))


def generate_report(data_file: str, output_file: str):
    """ç”Ÿæˆ HTML æŠ¥å‘Š"""
    
    with open(data_file, 'r') as f:
        data = json.load(f)
    
    metrics = data.get('metrics', {})
    
    # æå–æŒ‡æ ‡
    http_reqs = metrics.get('http_reqs', {}).get('values', {})
    http_duration = metrics.get('http_req_duration', {}).get('values', {})
    http_failed = metrics.get('http_req_failed', {}).get('values', {})
    
    # SLA æ£€æŸ¥
    sla_checks = [
        {
            'name': 'å¯ç”¨æ€§',
            'target': 'â‰¥ 99.9%',
            'actual': f"{(1 - http_failed.get('rate', 0)) * 100:.2f}%",
            'passed': http_failed.get('rate', 0) < 0.001,
        },
        {
            'name': 'P50 å»¶è¿Ÿ',
            'target': 'â‰¤ 50ms',
            'actual': f"{http_duration.get('p(50)', 0):.2f}ms",
            'passed': http_duration.get('p(50)', 0) <= 50,
        },
        {
            'name': 'P99 å»¶è¿Ÿ',
            'target': 'â‰¤ 200ms',
            'actual': f"{http_duration.get('p(99)', 0):.2f}ms",
            'passed': http_duration.get('p(99)', 0) <= 200,
        },
        {
            'name': 'é”™è¯¯ç‡',
            'target': 'â‰¤ 0.1%',
            'actual': f"{http_failed.get('rate', 0) * 100:.4f}%",
            'passed': http_failed.get('rate', 0) <= 0.001,
        },
    ]
    
    # é˜ˆå€¼æ£€æŸ¥
    thresholds = []
    for name, metric in metrics.items():
        if metric.get('thresholds'):
            for t_name, t_val in metric['thresholds'].items():
                thresholds.append({
                    'name': f"{name}: {t_name}",
                    'passed': t_val.get('ok', False),
                })
    
    # æ¸²æŸ“æ¨¡æ¿
    template = Template(REPORT_TEMPLATE)
    template.globals['format_number'] = format_number
    
    html = template.render(
        report_time=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        test_type='Load Test',
        duration=data.get('state', {}).get('testRunDurationMs', 0) / 1000,
        total_requests=http_reqs.get('count', 0),
        rps=http_reqs.get('rate', 0),
        avg_latency=http_duration.get('avg', 0),
        error_rate=http_failed.get('rate', 0) * 100,
        p50=http_duration.get('p(50)', 0),
        p90=http_duration.get('p(90)', 0),
        p95=http_duration.get('p(95)', 0),
        p99=http_duration.get('p(99)', 0),
        max_latency=http_duration.get('max', 0),
        sla_checks=sla_checks,
        thresholds=thresholds,
        rps_trend_labels=['0s', '30s', '60s', '90s', '120s'],  # ç¤ºä¾‹
        rps_trend_values=[50, 80, 100, 95, 100],  # ç¤ºä¾‹
    )
    
    with open(output_file, 'w') as f:
        f.write(html)
    
    print(f"Report generated: {output_file}")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Generate performance test report')
    parser.add_argument('input', help='K6 JSON output file')
    parser.add_argument('-o', '--output', default='report.html', help='Output HTML file')
    
    args = parser.parse_args()
    generate_report(args.input, args.output)
```

---

## 5. æµ‹è¯•è¿è¡Œè„šæœ¬ (load/scripts/run-tests.sh)

```bash
#!/bin/bash
# =============================================================================
# æ€§èƒ½æµ‹è¯•è¿è¡Œè„šæœ¬
# =============================================================================

set -euo pipefail

# é…ç½®
K6_VERSION="0.47.0"
BASE_URL="${BASE_URL:-http://localhost:8080}"
RESULTS_DIR="${RESULTS_DIR:-./results}"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# é¢œè‰²
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

log() {
    echo -e "${GREEN}[$(date '+%H:%M:%S')]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

# æ£€æŸ¥ K6 å®‰è£…
check_k6() {
    if ! command -v k6 &> /dev/null; then
        error "K6 not found. Please install K6 first."
        echo "  brew install k6  # macOS"
        echo "  docker pull grafana/k6  # Docker"
        exit 1
    fi
    log "K6 version: $(k6 version)"
}

# å¥åº·æ£€æŸ¥
health_check() {
    log "Checking target health: $BASE_URL/health"
    if ! curl -sf "$BASE_URL/health" > /dev/null; then
        error "Target is not healthy"
        exit 1
    fi
    log "Target is healthy"
}

# è¿è¡ŒåŸºçº¿æµ‹è¯•
run_baseline() {
    log "Running baseline test..."
    
    mkdir -p "$RESULTS_DIR"
    
    k6 run \
        --out json="$RESULTS_DIR/baseline_${TIMESTAMP}.json" \
        --env BASE_URL="$BASE_URL" \
        scenarios/baseline.js \
        2>&1 | tee "$RESULTS_DIR/baseline_${TIMESTAMP}.log"
    
    log "Baseline test completed"
}

# è¿è¡Œå‹åŠ›æµ‹è¯•
run_stress() {
    log "Running stress test..."
    
    mkdir -p "$RESULTS_DIR"
    
    k6 run \
        --out json="$RESULTS_DIR/stress_${TIMESTAMP}.json" \
        --env BASE_URL="$BASE_URL" \
        scenarios/stress.js \
        2>&1 | tee "$RESULTS_DIR/stress_${TIMESTAMP}.log"
    
    log "Stress test completed"
}

# è¿è¡Œå³°å€¼æµ‹è¯•
run_spike() {
    log "Running spike test..."
    
    mkdir -p "$RESULTS_DIR"
    
    k6 run \
        --out json="$RESULTS_DIR/spike_${TIMESTAMP}.json" \
        --env BASE_URL="$BASE_URL" \
        scenarios/spike.js \
        2>&1 | tee "$RESULTS_DIR/spike_${TIMESTAMP}.log"
    
    log "Spike test completed"
}

# ç”ŸæˆæŠ¥å‘Š
generate_reports() {
    log "Generating reports..."
    
    for json_file in "$RESULTS_DIR"/*.json; do
        if [[ -f "$json_file" ]]; then
            html_file="${json_file%.json}.html"
            python3 ../reports/generate-report.py "$json_file" -o "$html_file"
        fi
    done
    
    log "Reports generated in $RESULTS_DIR"
}

# ä¸»å‡½æ•°
main() {
    local test_type="${1:-baseline}"
    
    log "Starting performance test suite"
    log "Test type: $test_type"
    log "Target: $BASE_URL"
    
    check_k6
    health_check
    
    case "$test_type" in
        baseline)
            run_baseline
            ;;
        stress)
            run_stress
            ;;
        spike)
            run_spike
            ;;
        all)
            run_baseline
            run_stress
            run_spike
            ;;
        *)
            error "Unknown test type: $test_type"
            echo "Usage: $0 [baseline|stress|spike|all]"
            exit 1
            ;;
    esac
    
    generate_reports
    
    log "All tests completed!"
}

main "$@"
```

---

## æ³¨æ„äº‹é¡¹

1. K6 è„šæœ¬ä½¿ç”¨ ES6 æ¨¡å—è¯­æ³•
2. è‡ªå®šä¹‰æŒ‡æ ‡ç›‘æ§å…³é”®æ€§èƒ½ç‚¹
3. å‹åŠ›æµ‹è¯•é€æ­¥å¢åŠ è´Ÿè½½
4. æŠ¥å‘ŠåŒ…å« SLA æ£€æŸ¥ç»“æœ
5. æ”¯æŒ CI/CD é›†æˆ

## è¾“å‡ºè¦æ±‚

è¯·è¾“å‡ºå®Œæ•´çš„æ€§èƒ½æµ‹è¯•å¥—ä»¶ï¼ŒåŒ…å«ï¼š
1. K6 æµ‹è¯•è„šæœ¬
2. Locust æµ‹è¯•è„šæœ¬
3. æŠ¥å‘Šç”Ÿæˆå™¨
4. è¿è¡Œè„šæœ¬

